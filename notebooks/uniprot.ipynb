{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "378a5f47",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"This module defines a class and relative functions for mapping Uniprot\n",
    "sequences to PDB and Pfam databases.\"\"\"\n",
    "from rcsbapi.data import DataQuery as Query\n",
    "import os\n",
    "import re\n",
    "import dill as pickle\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import urllib.parse\n",
    "import requests \n",
    "import re\n",
    "import traceback\n",
    "\n",
    "import prody\n",
    "from prody import parsePDB, Atomic, queryUniprot\n",
    "from prody.utilities import openURL\n",
    "from Bio.pairwise2 import align as bioalign\n",
    "from Bio.pairwise2 import format_alignment\n",
    "\n",
    "from prody import LOGGER\n",
    "\n",
    "def searchUniprot(id):\n",
    "    \"\"\"Search Uniprot with *id* and return a :class:`UniprotRecord` containing the results. \n",
    "    \"\"\"\n",
    "    def _queryUniprot(*args, n_attempts=3, dt=1, **kwargs):\n",
    "        \"\"\"\n",
    "        Redefine prody function to check for no internet connection\n",
    "        \"\"\"\n",
    "        attempt = 0\n",
    "        while attempt < n_attempts:\n",
    "            try:\n",
    "                _ = openURL('http://www.uniprot.org/')\n",
    "                break\n",
    "            except:\n",
    "                LOGGER.info(\n",
    "                    f'Attempt {attempt} to contact www.uniprot.org failed')\n",
    "                attempt += 1\n",
    "                time.sleep((attempt+1)*dt)\n",
    "        else:\n",
    "            _ = openURL('http://www.uniprot.org/')\n",
    "        return queryUniprot(*args, **kwargs)\n",
    "\n",
    "    data = _queryUniprot(id)\n",
    "    return UniprotRecord(data)\n",
    "\n",
    "comma_splitter = re.compile(r'\\s*,\\s*').split\n",
    "ns = {'up': 'http://uniprot.org/uniprot'}\n",
    "    \n",
    "class UniprotRecord(object):\n",
    "    \"\"\"This class provides a wrapper for UniProt data including functions \n",
    "    for accessing particular fields and parsing associated PDB entries.\"\"\"\n",
    "    def __init__(self, data):\n",
    "        self._rawdata = data\n",
    "        self._pdbdata = []\n",
    "        self._parse()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<UniprotRecord: %s>'%self.getTitle()\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.getTitle()\n",
    "\n",
    "    def setData(self, value):\n",
    "        self._rawdata = value\n",
    "        self._parse()\n",
    "\n",
    "    def getData(self):\n",
    "        return self._rawdata\n",
    "\n",
    "    def getPDBs(self):\n",
    "        return self._pdbdata\n",
    "    \n",
    "    def getAccession(self, index=0):\n",
    "        \"\"\"accession tag\"\"\"\n",
    "        return self.getEntry('accession', index)\n",
    "    \n",
    "    def getName(self, index=0):\n",
    "        \"\"\"name tag\"\"\"\n",
    "        return self.getEntry('name', index)\n",
    "\n",
    "    def getProtein(self, index=0):\n",
    "        \"\"\"protein tag\n",
    "        <protein>\n",
    "            <recommendedName>\n",
    "                <fullName>Gap junction beta-2 protein</fullName>\n",
    "            </recommendedName>\n",
    "            <alternativeName>\n",
    "                <fullName evidence=\"57 58\">Connexin-26</fullName>\n",
    "                <shortName evidence=\"58\">Cx26</shortName>\n",
    "            </alternativeName>\n",
    "        </protein>\n",
    "        \"\"\"\n",
    "        protein = self.getEntry('protein', index)\n",
    "        \n",
    "        try:\n",
    "            recommend_elem = protein.find('up:recommendedName', ns)\n",
    "            alternative_elem = protein.find('up:recommendedName', ns)\n",
    "            \n",
    "            recommend_name = recommend_elem.find('up:fullName', ns)\n",
    "            alter_fullname = alternative_elem.find('up:fullName', ns)\n",
    "            alter_shortname = alternative_elem.find('up:shortName', ns)\n",
    "            \n",
    "            recommend_name = recommend_name.text if recommend_name is not None else None\n",
    "            alter_fullname = alter_fullname.text if alter_fullname is not None else None\n",
    "            alter_shortname = alter_shortname.text if alter_shortname is not None else None\n",
    "        except:\n",
    "            submitted_name = protein.find('up:submittedName/up:fullName', ns)\n",
    "            submitted_name = submitted_name.text if submitted_name is not None else None\n",
    "            recommend_name = submitted_name\n",
    "            alter_fullname = None\n",
    "            alter_shortname = None\n",
    "        \n",
    "        return {\n",
    "            'recommend_name': recommend_name,\n",
    "            'alter_fullname': alter_fullname,\n",
    "            'alter_shortname': alter_shortname            \n",
    "        }\n",
    "        \n",
    "    def getGene(self, index=0):\n",
    "        \"\"\"gene tag\n",
    "        <gene>\n",
    "            <name type=\"primary\">GJB2</name>\n",
    "        </gene>\n",
    "        \"\"\"\n",
    "        try:\n",
    "            gene = self.getEntry('gene', index)\n",
    "            name_elem = gene.find('up:name[@type=\"primary\"]', ns)\n",
    "            return name_elem.text if name_elem is not None else None\n",
    "        \n",
    "        except Exception as e:\n",
    "            LOGGER.warn(f'Error while parsing {id}: {e} -> None')\n",
    "            return None\n",
    "\n",
    "    def getOrganism(self, index=0):\n",
    "        \"\"\"organism tag\n",
    "        <organism>\n",
    "            <name type=\"scientific\">Homo sapiens</name>\n",
    "            <name type=\"common\">Human</name>\n",
    "            <dbReference type=\"NCBI Taxonomy\" id=\"9606\"/>\n",
    "            <lineage>\n",
    "                <taxon>Eukaryota</taxon>\n",
    "                <taxon>Metazoa</taxon>\n",
    "                <taxon>Chordata</taxon>\n",
    "                <taxon>Craniata</taxon>\n",
    "                <taxon>Vertebrata</taxon>\n",
    "                <taxon>Euteleostomi</taxon>\n",
    "                <taxon>Mammalia</taxon>\n",
    "                <taxon>Eutheria</taxon>\n",
    "                <taxon>Euarchontoglires</taxon>\n",
    "                <taxon>Primates</taxon>\n",
    "                <taxon>Haplorrhini</taxon>\n",
    "                <taxon>Catarrhini</taxon>\n",
    "                <taxon>Hominidae</taxon>\n",
    "                <taxon>Homo</taxon>\n",
    "            </lineage>\n",
    "        </organism>\n",
    "        \"\"\"\n",
    "        organism = self.getEntry('organism', index)\n",
    "\n",
    "        sci_name = organism.find('up:name[@type=\"scientific\"]', ns)\n",
    "        com_name = organism.find('up:name[@type=\"common\"]', ns)\n",
    "        db_ref = organism.find('up:dbReference[@type=\"NCBI Taxonomy\"]', ns)\n",
    "        lineage_tags = organism.findall('up:lineage/up:taxon', ns)\n",
    "\n",
    "        return {\n",
    "            'scientific_name': sci_name.text.strip() if sci_name is not None else None,\n",
    "            'common_name': com_name.text.strip() if com_name is not None else None,\n",
    "            'taxonomy_id': db_ref.attrib['id'] if db_ref is not None else None,\n",
    "            'lineage': [taxon.text.strip() for taxon in lineage_tags if taxon.text]\n",
    "        }\n",
    "        \n",
    "    def getCellLocation(self):\n",
    "        return self._cell_location\n",
    "        \n",
    "    def getReference(self, index=0):\n",
    "        \"\"\"reference tag\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def getComment(self, index=0):\n",
    "        \"\"\"conmment tag\"\"\"\n",
    "        pass\n",
    "        \n",
    "    def getDBreference(self, index=0):\n",
    "        \"\"\"dbReference tag\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def getProteinExistence(self, index=0):\n",
    "        \"\"\"proteinExistence tag\"\"\"\n",
    "        pass\n",
    "     \n",
    "    def getKeyword(self, index=0):\n",
    "        \"\"\"keyword tag\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def getFeature(self, index=0):\n",
    "        \"\"\"feature tag\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def getEvidence(self, index=0):\n",
    "        \"\"\"evidence tag\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def getSequence(self, index=0):\n",
    "        return self.getEntry('sequence', index)\n",
    "    \n",
    "    def getZincFinger(self):\n",
    "        return self._zinc_finger\n",
    "    \n",
    "    def getDNAbinding(self):\n",
    "        return self._dna_binding\n",
    "    \n",
    "    def getActivateSite(self):\n",
    "        return self._active_site\n",
    "    \n",
    "    def getBindingSite(self):\n",
    "        return self._binding_site\n",
    "    \n",
    "    def getSite(self):\n",
    "        return self._site\n",
    "    \n",
    "    def getAlphaFold(self):\n",
    "        \"\"\"<dbReference type=\"AlphaFoldDB\" id=\"Q9UDY8\"/>\"\"\"\n",
    "        AlphaFoldDB = None\n",
    "        for key, value in self._rawdata.items():\n",
    "            if not key.startswith('dbReference'):\n",
    "                continue\n",
    "\n",
    "            if type(value) != list or len(value) != 2:\n",
    "                continue\n",
    "            \n",
    "            # [('type', 'AlphaFoldDB'), ('id', 'Q13509')]\n",
    "            if value[0][1] == 'AlphaFoldDB':\n",
    "                AlphaFoldDB = value[1][1]\n",
    "                break\n",
    "        return AlphaFoldDB\n",
    "    \n",
    "    def getCofactor(self):\n",
    "        return self._cofactors\n",
    "    \n",
    "    def getTitle(self):\n",
    "        uid = self.getAccession()\n",
    "        name = self.getName()\n",
    "        return '%s (%s)'%(uid, name)\n",
    "\n",
    "    def getEntry(self, item, index=0):\n",
    "        key = '%s%4d'%(item, index)\n",
    "        if key in self._rawdata:\n",
    "            return self._rawdata[key]\n",
    "        else:\n",
    "            raise KeyError('%s does not exist in the Uniprot record'%key)\n",
    "\n",
    "    def _parseDNAbinding(self):\n",
    "        data = self._rawdata\n",
    "        dna_binding = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            if value.get('type') != \"DNA-binding region\":\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <feature type=\"DNA-binding region\" description=\"HMG box 1\" evidence=\"4\">\n",
    "                <location>\n",
    "                <begin position=\"9\"/>\n",
    "                <end position=\"79\"/>\n",
    "                </location>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            descp = value.get('description')\n",
    "            begin_elem = value.find('up:location/up:begin', ns)\n",
    "            end_elem = value.find('up:location/up:end', ns)\n",
    "            begin = begin_elem.attrib.get('position') if begin_elem is not None else None\n",
    "            end = end_elem.attrib.get('position') if end_elem is not None else None\n",
    "            dna_binding.append({\n",
    "                'description': descp, \n",
    "                'begin': begin, \n",
    "                'end': end\n",
    "            })\n",
    "        self._dna_binding = dna_binding\n",
    "            \n",
    "    def _parseZincfinger(self):\n",
    "        data = self._rawdata\n",
    "        zinc_finger = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            if value.get('type') != \"zinc finger region\":\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <feature type=\"zinc finger region\" description=\"C2H2-type 1\" evidence=\"1\">\n",
    "                <location>\n",
    "                <begin position=\"110\"/>\n",
    "                <end position=\"133\"/>\n",
    "                </location>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            descp = value.get('description')\n",
    "            begin_elem = value.find('up:location/up:begin', ns)\n",
    "            end_elem = value.find('up:location/up:end', ns)\n",
    "            begin = begin_elem.attrib.get('position') if begin_elem is not None else None\n",
    "            end = end_elem.attrib.get('position') if end_elem is not None else None\n",
    "            zinc_finger.append({\n",
    "                'description': descp, \n",
    "                'begin': begin, \n",
    "                'end': end\n",
    "            })\n",
    "        self._zinc_finger = zinc_finger\n",
    "\n",
    "    def _parseActiveSite(self):\n",
    "        data = self._rawdata\n",
    "        active_site = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            \n",
    "            if value.get('type') != \"active site\":\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <feature type=\"active site\" description=\"Proton donor\" evidence=\"2\">\n",
    "                <location>\n",
    "                <position position=\"613\"/>\n",
    "                </location>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            descp = value.get('description')\n",
    "            pos_elem = value.find('up:location/up:position', ns)\n",
    "            pos   = int(pos_elem.attrib.get('position')) if pos_elem is not None else None\n",
    "            active_site.append({\n",
    "                'description': descp, \n",
    "                'position': pos\n",
    "            })\n",
    "        self._active_site = active_site\n",
    "    \n",
    "    def _parseBindingSite(self):\n",
    "        data = self._rawdata\n",
    "        binding_site = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            \n",
    "            if value.get('type') != \"binding site\":\n",
    "                continue\n",
    "            \n",
    "            \"\"\"\n",
    "            <feature type=\"binding site\" evidence=\"7 9 22 23 24\">\n",
    "                <location>\n",
    "                <position position=\"617\"/>\n",
    "                </location>\n",
    "                <ligand>\n",
    "                <name>Zn(2+)</name>\n",
    "                <dbReference type=\"ChEBI\" id=\"CHEBI:29105\"/>\n",
    "                </ligand>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            pos_elem = value.find('up:location/up:position', ns)\n",
    "            pos   = int(pos_elem.attrib.get('position')) if pos_elem is not None else None\n",
    "            \n",
    "            ligand_elem = value.find('up:ligand', ns)\n",
    "            ligand_name = ligand_elem.find('up:name', ns)\n",
    "            ligand_name = ligand_name.text if ligand_name is not None else None\n",
    "            ligand_chebi= ligand_elem.find('up:dbReference[@type=\"ChEBI\"]', ns)\n",
    "            ligand_chebi = ligand_chebi.attrib['id'] if ligand_chebi is not None else None\n",
    "            binding_site.append({\n",
    "                'position': pos, \n",
    "                'name': ligand_name, \n",
    "                'chebi': ligand_chebi\n",
    "            })\n",
    "        self._binding_site = binding_site\n",
    "    \n",
    "    def _parseSite(self):\n",
    "        data = self._rawdata\n",
    "        site = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            \n",
    "            if value.get('type') != \"site\":\n",
    "                continue\n",
    "            \n",
    "            \"\"\"\n",
    "            <feature type=\"site\" description=\"Breakpoint for translocation to form BIRC2-MALT1\">\n",
    "                <location>\n",
    "                    <begin position=\"323\"/>\n",
    "                    <end position=\"324\"/>\n",
    "                </location>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            descp = value.get('description')\n",
    "            begin_elem = value.find('up:location/up:begin', ns)\n",
    "            end_elem = value.find('up:location/up:end', ns)\n",
    "            begin = begin_elem.attrib.get('position') if begin_elem is not None else None\n",
    "            end = end_elem.attrib.get('position') if end_elem is not None else None\n",
    "            site.append({\n",
    "                'description': descp, \n",
    "                'begin': begin, \n",
    "                'end': end\n",
    "            })\n",
    "        self._site = site\n",
    "    \n",
    "    def _parseCofactor(self):\n",
    "        data = self._rawdata\n",
    "        cofactors = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('comment'):\n",
    "                continue\n",
    "            \n",
    "            if type(value) == list:\n",
    "                continue\n",
    "            \n",
    "            if value.get('type') != \"cofactor\":\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <comment type=\"cofactor\">\n",
    "                <cofactor evidence=\"2\">\n",
    "                    <name>cf_name</name>\n",
    "                    <dbReference type=\"ChEBI\" id=cf_chebi/>\n",
    "                </cofactor>\n",
    "            </comment>\n",
    "            \"\"\"\n",
    "            cf_elem = value.find('up:cofactor', ns)\n",
    "            # ---\n",
    "            cf_name = cf_elem.find('up:name', ns)\n",
    "            cf_chebi= cf_elem.find('up:dbReference[@type=\"ChEBI\"]', ns)\n",
    "            cf_chebi = cf_chebi.attrib['id'] if cf_chebi is not None else None\n",
    "            # ---\n",
    "            cofactors.append({\n",
    "                'name': cf_name.text, \n",
    "                'chebi': cf_chebi\n",
    "            })\n",
    "        self._cofactors = cofactors\n",
    "    \n",
    "    def _parseCellLocation(self):\n",
    "        data = self._rawdata\n",
    "        cell_location = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            \n",
    "            type_list = ['topological domain', 'transmembrane region', 'intramembrane region']\n",
    "            loc_type  = value.get('type')\n",
    "            if loc_type not in type_list:\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <feature type=\"intramembrane region\" evidence=\"45\">\n",
    "                <location>\n",
    "                <begin position=\"2\"/>\n",
    "                <end position=\"13\"/>\n",
    "                </location>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            descp = value.get('description')\n",
    "            begin_elem = value.find('up:location/up:begin', ns)\n",
    "            end_elem = value.find('up:location/up:end', ns)\n",
    "            begin = begin_elem.attrib.get('position') if begin_elem is not None else None\n",
    "            end = end_elem.attrib.get('position') if end_elem is not None else None\n",
    "            cell_location.append({\n",
    "                'type': loc_type,\n",
    "                'description': descp, \n",
    "                'begin': begin, \n",
    "                'end': end\n",
    "            })\n",
    "        self._cell_location = cell_location\n",
    "\n",
    "    def _parseSeqAnnotfromPDB(self, pdb_instances):\n",
    "        \"\"\"pdb_instances ['1AID.A', '1AID.B']\n",
    "        \"\"\"\n",
    "        query = Query(\n",
    "            input_type=\"polymer_entity_instances\",\n",
    "            input_ids=pdb_instances,\n",
    "            return_data_list=[\n",
    "                \"polymer_entity_instances.rcsb_id\",\n",
    "                \"rcsb_polymer_instance_feature.type\",\n",
    "                \"rcsb_polymer_instance_feature.feature_positions.beg_seq_id\",\n",
    "                \"rcsb_polymer_instance_feature.feature_positions.end_seq_id\",\n",
    "                \n",
    "                'rcsb_polymer_instance_info.modeled_residue_count',\n",
    "                'rcsb_polymer_instance_feature_summary.coverage',\n",
    "                'rcsb_polymer_instance_feature_summary.type',\n",
    "                'polymer_entity.rcsb_polymer_entity.pdbx_mutation',\n",
    "                'polymer_entity.entity_poly.rcsb_mutation_count',\n",
    "            ]\n",
    "        )\n",
    "        r = query.exec()\n",
    "\n",
    "        out = {}\n",
    "        for entry in r['data']['polymer_entity_instances']:\n",
    "            instance = entry['rcsb_id']\n",
    "            instance_feature = entry.get('rcsb_polymer_instance_feature', None)\n",
    "                \n",
    "            unobs_res = [ele['feature_positions'] for ele in instance_feature if ele['type'] == 'UNOBSERVED_RESIDUE_XYZ']\n",
    "            unobs_atom= [ele['feature_positions'] for ele in instance_feature if ele['type'] == 'UNOBSERVED_ATOM_XYZ']\n",
    "            \n",
    "            # Turn into a list of residues / atoms\n",
    "            unobs_res = [\n",
    "                i for block in unobs_res for r in block\n",
    "                for i in range(r['beg_seq_id'], r['end_seq_id'] + 1)\n",
    "            ]\n",
    "            unobs_atom = [\n",
    "                i for block in unobs_atom for r in block\n",
    "                for i in range(r['beg_seq_id'], r['end_seq_id'] + 1)\n",
    "            ]\n",
    "            \n",
    "            # Extract specific types\n",
    "            coverage_field = entry['rcsb_polymer_instance_feature_summary']    \n",
    "            unobs_res_cov = next((d['coverage'] for d in coverage_field if d['type'] == 'UNOBSERVED_RESIDUE_XYZ'), 0)\n",
    "            unobs_atom_cov = next((d['coverage'] for d in coverage_field if d['type'] == 'UNOBSERVED_ATOM_XYZ'), 0)\n",
    "\n",
    "            coverage = {\n",
    "                \"unobs_res\": unobs_res_cov,\n",
    "                \"unobs_atom\": unobs_atom_cov\n",
    "            }\n",
    "            \n",
    "            modeled_residue_count = entry['rcsb_polymer_instance_info']['modeled_residue_count']\n",
    "            pdbx_mutation = entry['polymer_entity']['rcsb_polymer_entity']['pdbx_mutation']\n",
    "            rcsb_mutation_count = entry['polymer_entity']['entity_poly']['rcsb_mutation_count']\n",
    "            \n",
    "            out[instance] = {\n",
    "                'unobs_res': unobs_res,\n",
    "                'unobs_atom': unobs_atom,\n",
    "                'coverage': coverage,\n",
    "                'modeled_residue_count': modeled_residue_count,\n",
    "                'pdbx_mutation': pdbx_mutation,\n",
    "                'rcsb_mutation_count': rcsb_mutation_count,\n",
    "            }\n",
    "        return out\n",
    "\n",
    "    def _parseLigandsfromPDB(self, pdblist):\n",
    "        query = Query(\n",
    "            input_type=\"entries\",\n",
    "            input_ids=pdblist,\n",
    "            return_data_list=[\n",
    "                \"nonpolymer_entities.pdbx_entity_nonpoly.comp_id\",\n",
    "                \"nonpolymer_entities.pdbx_entity_nonpoly.name\",\n",
    "                \"nonpolymer_entities.rcsb_nonpolymer_entity.pdbx_description\",\n",
    "            ]\n",
    "        )\n",
    "        r = query.exec()\n",
    "        \n",
    "        out = {}\n",
    "        for entry in r['data']['entries']:\n",
    "            pdbid = entry['rcsb_id']\n",
    "            ligand_list = entry.get('nonpolymer_entities', None)\n",
    "            # Return None if no ligand\n",
    "            if ligand_list is None:\n",
    "                out[pdbid] = None\n",
    "                continue\n",
    "            \n",
    "            out[pdbid] = []\n",
    "            for entity in ligand_list:\n",
    "                _dict = {\n",
    "                    'comp_id': entity['pdbx_entity_nonpoly']['comp_id'],\n",
    "                    'name': entity['pdbx_entity_nonpoly']['name'],\n",
    "                    'pdbx_description': entity['rcsb_nonpolymer_entity']['pdbx_description']\n",
    "                }\n",
    "                out[pdbid].append(_dict)\n",
    "        return out\n",
    "\n",
    "    def _parseRvaluefromPDB(self, pdblist):\n",
    "        query = Query(\n",
    "            input_type=\"entries\",\n",
    "            input_ids=pdblist,\n",
    "            return_data_list=[\n",
    "                \"rcsb_accession_info.initial_release_date\",\n",
    "                \"refine.ls_R_factor_R_free\",\n",
    "                \"refine.ls_R_factor_R_work\",\n",
    "                \"refine.ls_R_factor_obs\",\n",
    "                ]\n",
    "        )\n",
    "        r = query.exec()\n",
    "        \n",
    "        out = {}\n",
    "        for entry in r['data']['entries']:\n",
    "            pdbid = entry['rcsb_id']\n",
    "            rcsb_accession_info = entry.get('rcsb_accession_info', None)\n",
    "            # Return None if no ligand\n",
    "            if rcsb_accession_info is None:\n",
    "                initial_release_date = None\n",
    "            else:\n",
    "                initial_release_date = rcsb_accession_info['initial_release_date']\n",
    "                \n",
    "            refine = entry.get('refine', None)\n",
    "            # Return None if no refine\n",
    "            if refine is None:\n",
    "                ls_R_factor_R_free = None\n",
    "                ls_R_factor_R_work = None\n",
    "                ls_R_factor_obs = None\n",
    "            else:\n",
    "                refine_info = refine[0]\n",
    "                ls_R_factor_R_free = refine_info['ls_R_factor_R_free']\n",
    "                ls_R_factor_R_work = refine_info['ls_R_factor_R_work']\n",
    "                ls_R_factor_obs    = refine_info['ls_R_factor_obs']\n",
    "                \n",
    "            out[pdbid] = {\n",
    "                'initial_release_date': initial_release_date,\n",
    "                'ls_R_factor_R_free': ls_R_factor_R_free,\n",
    "                'ls_R_factor_R_work': ls_R_factor_R_work,\n",
    "                'ls_R_factor_obs': ls_R_factor_obs,\n",
    "            }\n",
    "        return out\n",
    "    \n",
    "    def _parsePDB(self):\n",
    "        data = self._rawdata\n",
    "        PDBdata = {}\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('dbReference'):\n",
    "                continue\n",
    "            try:\n",
    "                pdbid = value['PDB']\n",
    "            except (KeyError, TypeError) as e:\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <dbReference type=\"PDB\" id=pdbid>\n",
    "                <property type=\"method\" value=\"EM\"/>\n",
    "                <property type=\"resolution\" value=resolution/>\n",
    "                <property type=\"chains\" value=pdbchains/>\n",
    "    \t\t</dbReference>\n",
    "            \"\"\"\n",
    "            method = value['method']\n",
    "            method = value.get('method', None)\n",
    "            # pdbchains = value['chains'] # e.g. \"B/D/F/G/H/I=1-450\"\n",
    "            pdbchains = value.get('chains', []) # e.g. \"B/D/F/G/H/I=1-450\"\n",
    "            resolution = value.get('resolution', '1.00 A')\n",
    "            resolution = float(resolution.split(' ')[0])\n",
    "            \n",
    "            # example chain strings: \"A=27-139, B=140-150\" or \"A/B=27-150\"\n",
    "            chains = []\n",
    "            resrange = None\n",
    "            try:\n",
    "                pdbchains = comma_splitter(pdbchains)\n",
    "                for chain in pdbchains:\n",
    "                    chids, resrange = chain.split('=')\n",
    "                    chids = [chid.strip() for chid in chids.split('/')]\n",
    "                    for chid in chids:\n",
    "                        chains.append(chid)\n",
    "            except Exception as e:\n",
    "                LOGGER.warn(str(e))\n",
    "                LOGGER.warn('Suspected no chain information')\n",
    "                    \n",
    "            PDBdata[pdbid] = {\n",
    "                'method': method,\n",
    "                'resolution': resolution,\n",
    "                'chains': chains,\n",
    "                'resrange': resrange,\n",
    "            }\n",
    "\n",
    "        pdblist = list(PDBdata.keys())\n",
    "        if len(pdblist) == 0:\n",
    "            self._pdbdata = PDBdata\n",
    "            return\n",
    "        \n",
    "        # RCSB Data API: entries \n",
    "        # Retrieved info: ligands, released date, Observed Residual factor (R-value obs) \n",
    "        ligands = self._parseLigandsfromPDB(pdblist)\n",
    "        rvalues = self._parseRvaluefromPDB(pdblist)\n",
    "        \n",
    "        # fetchAsymIDs to convert auth_asym_ids into label_asym_id\n",
    "        auth2label = self.fetchAsymIDs(pdblist)\n",
    "        \n",
    "        for pdbid in PDBdata:\n",
    "            PDBdata[pdbid]['ligand'] = ligands[pdbid]\n",
    "            PDBdata[pdbid]['initial_release_date'] = rvalues[pdbid]['initial_release_date']\n",
    "            PDBdata[pdbid]['ls_R_factor_R_free'] = rvalues[pdbid]['ls_R_factor_R_free']\n",
    "            PDBdata[pdbid]['ls_R_factor_R_work'] = rvalues[pdbid]['ls_R_factor_R_work']\n",
    "            PDBdata[pdbid]['ls_R_factor_obs'] = rvalues[pdbid]['ls_R_factor_obs']\n",
    "            \n",
    "            # fetchAsymIDs to convert auth_asym_ids into label_asym_id\n",
    "            chains = PDBdata[pdbid]['chains']\n",
    "            chain_dict = auth2label.get(pdbid, None)\n",
    "            if chain_dict is None:\n",
    "                LOGGER.warn(f'fetchAsymIDs: No infor. of {pdbid}')\n",
    "            else:\n",
    "                chains = [chain_dict.get(chid, chid) for chid in chains]\n",
    "            \n",
    "            # RCSB Data API: polymer_entity_instances \n",
    "            # Retrieved info: Sequence Annotations - UNOBSERVED_RESIDUE_XYZ\n",
    "            pdb_instances = [f'{pdbid}.{chid}' for chid in chains]\n",
    "            if len(pdb_instances) > 0:\n",
    "                seq_annot = self._parseSeqAnnotfromPDB(pdb_instances)\n",
    "            else:\n",
    "                seq_annot = None\n",
    "            PDBdata[pdbid]['seq_annot'] = seq_annot\n",
    "        self._pdbdata = PDBdata\n",
    "    \n",
    "    def fetchAsymIDs(self, pdblist):\n",
    "        \"\"\"\n",
    "        Convert auth_asym_ids into label_asym_id. \n",
    "        https://www.rcsb.org/docs/general-help/identifiers-in-pdb#:~:text=type%20of%20entity.-,Macromolecular%20Instance%20ID,R%2C%20while%20the%20PDB%20assigned%20ones%20are%20C%20and%20D%20respectively.,-The%20polymer%20sequences\n",
    "        \n",
    "        Return: dict\n",
    "            given auth_asym_ids, dict can be used as a look up table to find label_asym_id.\n",
    "        \"\"\"\n",
    "        query = Query(\n",
    "            input_type=\"entries\",\n",
    "            input_ids=pdblist,\n",
    "            return_data_list=[\n",
    "                \"polymer_entities.polymer_entity_instances.rcsb_id\",\n",
    "                \"polymer_entities.rcsb_polymer_entity_container_identifiers.auth_asym_ids\",\n",
    "            ]\n",
    "        )\n",
    "        r = query.exec()\n",
    "\n",
    "        if len(r['data']['entries']) == 0:\n",
    "            LOGGER.warn(f'fetchAsymIDs: Check input {pdblist}')\n",
    "            return {}\n",
    "\n",
    "        auth2label = {}\n",
    "        for entry in r['data']['entries']:\n",
    "            pdbid = entry['rcsb_id']\n",
    "            \n",
    "            _dict = {}\n",
    "            for entity in entry['polymer_entities']:\n",
    "                label_asym_id = entity['polymer_entity_instances'][0]['rcsb_id'].split('.')[-1]\n",
    "                auth_asym_id  = entity['rcsb_polymer_entity_container_identifiers']['auth_asym_ids'][0]\n",
    "                _dict[auth_asym_id] = label_asym_id\n",
    "            \n",
    "            auth2label[pdbid] = _dict\n",
    "        return auth2label\n",
    "\n",
    "    def _parse(self):\n",
    "        LOGGER.info(f'Parse UniProt information of {self.getAccession()}...')\n",
    "        LOGGER.timeit('_parse')\n",
    "        self._parseActiveSite()\n",
    "        self._parseBindingSite()\n",
    "        self._parseSite()\n",
    "        self._parseCofactor()\n",
    "        self._parseDNAbinding()\n",
    "        self._parseZincfinger()\n",
    "        self._parseCellLocation()\n",
    "        self._parsePDB()\n",
    "        LOGGER.report(f'Parsing in %.1fs.', '_parse')\n",
    "\n",
    "def searchUniprot(id):\n",
    "    \"\"\"Search Uniprot with *id* and return a :class:`UniprotRecord` containing the results. \n",
    "    \"\"\"\n",
    "    def _queryUniprot(*args, n_attempts=3, dt=1, **kwargs):\n",
    "        \"\"\"\n",
    "        Redefine prody function to check for no internet connection\n",
    "        \"\"\"\n",
    "        attempt = 0\n",
    "        while attempt < n_attempts:\n",
    "            try:\n",
    "                _ = openURL('http://www.uniprot.org/')\n",
    "                break\n",
    "            except:\n",
    "                LOGGER.info(\n",
    "                    f'Attempt {attempt} to contact www.uniprot.org failed')\n",
    "                attempt += 1\n",
    "                time.sleep((attempt+1)*dt)\n",
    "        else:\n",
    "            _ = openURL('http://www.uniprot.org/')\n",
    "        return queryUniprot(*args, **kwargs)\n",
    "\n",
    "    data = _queryUniprot(id)\n",
    "    return UniprotRecord(data)\n",
    "\n",
    "comma_splitter = re.compile(r'\\s*,\\s*').split\n",
    "ns = {'up': 'http://uniprot.org/uniprot'}\n",
    "    \n",
    "class UniprotRecord(object):\n",
    "    \"\"\"This class provides a wrapper for UniProt data including functions \n",
    "    for accessing particular fields and parsing associated PDB entries.\"\"\"\n",
    "    def __init__(self, data):\n",
    "        self._rawdata = data\n",
    "        self._pdbdata = []\n",
    "        self._parse()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<UniprotRecord: %s>'%self.getTitle()\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.getTitle()\n",
    "\n",
    "    def setData(self, value):\n",
    "        self._rawdata = value\n",
    "        self._parse()\n",
    "\n",
    "    def getData(self):\n",
    "        return self._rawdata\n",
    "\n",
    "    def getPDBs(self):\n",
    "        return self._pdbdata\n",
    "    \n",
    "    def getAccession(self, index=0):\n",
    "        \"\"\"accession tag\"\"\"\n",
    "        return self.getEntry('accession', index)\n",
    "    \n",
    "    def getName(self, index=0):\n",
    "        \"\"\"name tag\"\"\"\n",
    "        return self.getEntry('name', index)\n",
    "\n",
    "    def getProtein(self, index=0):\n",
    "        \"\"\"protein tag\n",
    "        <protein>\n",
    "            <recommendedName>\n",
    "                <fullName>Gap junction beta-2 protein</fullName>\n",
    "            </recommendedName>\n",
    "            <alternativeName>\n",
    "                <fullName evidence=\"57 58\">Connexin-26</fullName>\n",
    "                <shortName evidence=\"58\">Cx26</shortName>\n",
    "            </alternativeName>\n",
    "        </protein>\n",
    "        \"\"\"\n",
    "        protein = self.getEntry('protein', index)\n",
    "        \n",
    "        try:\n",
    "            recommend_elem = protein.find('up:recommendedName', ns)\n",
    "            alternative_elem = protein.find('up:recommendedName', ns)\n",
    "            \n",
    "            recommend_name = recommend_elem.find('up:fullName', ns)\n",
    "            alter_fullname = alternative_elem.find('up:fullName', ns)\n",
    "            alter_shortname = alternative_elem.find('up:shortName', ns)\n",
    "            \n",
    "            recommend_name = recommend_name.text if recommend_name is not None else None\n",
    "            alter_fullname = alter_fullname.text if alter_fullname is not None else None\n",
    "            alter_shortname = alter_shortname.text if alter_shortname is not None else None\n",
    "        except:\n",
    "            submitted_name = protein.find('up:submittedName/up:fullName', ns)\n",
    "            submitted_name = submitted_name.text if submitted_name is not None else None\n",
    "            recommend_name = submitted_name\n",
    "            alter_fullname = None\n",
    "            alter_shortname = None\n",
    "        \n",
    "        return {\n",
    "            'recommend_name': recommend_name,\n",
    "            'alter_fullname': alter_fullname,\n",
    "            'alter_shortname': alter_shortname            \n",
    "        }\n",
    "        \n",
    "    def getGene(self, index=0):\n",
    "        \"\"\"gene tag\n",
    "        <gene>\n",
    "            <name type=\"primary\">GJB2</name>\n",
    "        </gene>\n",
    "        \"\"\"\n",
    "        try:\n",
    "            gene = self.getEntry('gene', index)\n",
    "            name_elem = gene.find('up:name[@type=\"primary\"]', ns)\n",
    "            return name_elem.text if name_elem is not None else None\n",
    "        \n",
    "        except Exception as e:\n",
    "            LOGGER.warn(f'Error while parsing {id}: {e} -> None')\n",
    "            return None\n",
    "\n",
    "    def getOrganism(self, index=0):\n",
    "        \"\"\"organism tag\n",
    "        <organism>\n",
    "            <name type=\"scientific\">Homo sapiens</name>\n",
    "            <name type=\"common\">Human</name>\n",
    "            <dbReference type=\"NCBI Taxonomy\" id=\"9606\"/>\n",
    "            <lineage>\n",
    "                <taxon>Eukaryota</taxon>\n",
    "                <taxon>Metazoa</taxon>\n",
    "                <taxon>Chordata</taxon>\n",
    "                <taxon>Craniata</taxon>\n",
    "                <taxon>Vertebrata</taxon>\n",
    "                <taxon>Euteleostomi</taxon>\n",
    "                <taxon>Mammalia</taxon>\n",
    "                <taxon>Eutheria</taxon>\n",
    "                <taxon>Euarchontoglires</taxon>\n",
    "                <taxon>Primates</taxon>\n",
    "                <taxon>Haplorrhini</taxon>\n",
    "                <taxon>Catarrhini</taxon>\n",
    "                <taxon>Hominidae</taxon>\n",
    "                <taxon>Homo</taxon>\n",
    "            </lineage>\n",
    "        </organism>\n",
    "        \"\"\"\n",
    "        organism = self.getEntry('organism', index)\n",
    "\n",
    "        sci_name = organism.find('up:name[@type=\"scientific\"]', ns)\n",
    "        com_name = organism.find('up:name[@type=\"common\"]', ns)\n",
    "        db_ref = organism.find('up:dbReference[@type=\"NCBI Taxonomy\"]', ns)\n",
    "        lineage_tags = organism.findall('up:lineage/up:taxon', ns)\n",
    "\n",
    "        return {\n",
    "            'scientific_name': sci_name.text.strip() if sci_name is not None else None,\n",
    "            'common_name': com_name.text.strip() if com_name is not None else None,\n",
    "            'taxonomy_id': db_ref.attrib['id'] if db_ref is not None else None,\n",
    "            'lineage': [taxon.text.strip() for taxon in lineage_tags if taxon.text]\n",
    "        }\n",
    "        \n",
    "    def getCellLocation(self):\n",
    "        return self._cell_location\n",
    "        \n",
    "    def getReference(self, index=0):\n",
    "        \"\"\"reference tag\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def getComment(self, index=0):\n",
    "        \"\"\"conmment tag\"\"\"\n",
    "        pass\n",
    "        \n",
    "    def getDBreference(self, index=0):\n",
    "        \"\"\"dbReference tag\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def getProteinExistence(self, index=0):\n",
    "        \"\"\"proteinExistence tag\"\"\"\n",
    "        pass\n",
    "     \n",
    "    def getKeyword(self, index=0):\n",
    "        \"\"\"keyword tag\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def getFeature(self, index=0):\n",
    "        \"\"\"feature tag\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def getEvidence(self, index=0):\n",
    "        \"\"\"evidence tag\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def getSequence(self, index=0):\n",
    "        return self.getEntry('sequence', index)\n",
    "    \n",
    "    def getZincFinger(self):\n",
    "        return self._zinc_finger\n",
    "    \n",
    "    def getDNAbinding(self):\n",
    "        return self._dna_binding\n",
    "    \n",
    "    def getActivateSite(self):\n",
    "        return self._active_site\n",
    "    \n",
    "    def getBindingSite(self):\n",
    "        return self._binding_site\n",
    "    \n",
    "    def getSite(self):\n",
    "        return self._site\n",
    "    \n",
    "    def getAlphaFold(self):\n",
    "        \"\"\"<dbReference type=\"AlphaFoldDB\" id=\"Q9UDY8\"/>\"\"\"\n",
    "        AlphaFoldDB = None\n",
    "        for key, value in self._rawdata.items():\n",
    "            if not key.startswith('dbReference'):\n",
    "                continue\n",
    "\n",
    "            if type(value) != list or len(value) != 2:\n",
    "                continue\n",
    "            \n",
    "            # [('type', 'AlphaFoldDB'), ('id', 'Q13509')]\n",
    "            if value[0][1] == 'AlphaFoldDB':\n",
    "                AlphaFoldDB = value[1][1]\n",
    "                break\n",
    "        return AlphaFoldDB\n",
    "    \n",
    "    def getCofactor(self):\n",
    "        return self._cofactors\n",
    "    \n",
    "    def getTitle(self):\n",
    "        uid = self.getAccession()\n",
    "        name = self.getName()\n",
    "        return '%s (%s)'%(uid, name)\n",
    "\n",
    "    def getEntry(self, item, index=0):\n",
    "        key = '%s%4d'%(item, index)\n",
    "        if key in self._rawdata:\n",
    "            return self._rawdata[key]\n",
    "        else:\n",
    "            raise KeyError('%s does not exist in the Uniprot record'%key)\n",
    "\n",
    "    def _parseDNAbinding(self):\n",
    "        data = self._rawdata\n",
    "        dna_binding = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            if value.get('type') != \"DNA-binding region\":\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <feature type=\"DNA-binding region\" description=\"HMG box 1\" evidence=\"4\">\n",
    "                <location>\n",
    "                <begin position=\"9\"/>\n",
    "                <end position=\"79\"/>\n",
    "                </location>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            descp = value.get('description')\n",
    "            begin_elem = value.find('up:location/up:begin', ns)\n",
    "            end_elem = value.find('up:location/up:end', ns)\n",
    "            begin = begin_elem.attrib.get('position') if begin_elem is not None else None\n",
    "            end = end_elem.attrib.get('position') if end_elem is not None else None\n",
    "            dna_binding.append({\n",
    "                'description': descp, \n",
    "                'begin': begin, \n",
    "                'end': end\n",
    "            })\n",
    "        self._dna_binding = dna_binding\n",
    "            \n",
    "    def _parseZincfinger(self):\n",
    "        data = self._rawdata\n",
    "        zinc_finger = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            if value.get('type') != \"zinc finger region\":\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <feature type=\"zinc finger region\" description=\"C2H2-type 1\" evidence=\"1\">\n",
    "                <location>\n",
    "                <begin position=\"110\"/>\n",
    "                <end position=\"133\"/>\n",
    "                </location>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            descp = value.get('description')\n",
    "            begin_elem = value.find('up:location/up:begin', ns)\n",
    "            end_elem = value.find('up:location/up:end', ns)\n",
    "            begin = begin_elem.attrib.get('position') if begin_elem is not None else None\n",
    "            end = end_elem.attrib.get('position') if end_elem is not None else None\n",
    "            zinc_finger.append({\n",
    "                'description': descp, \n",
    "                'begin': begin, \n",
    "                'end': end\n",
    "            })\n",
    "        self._zinc_finger = zinc_finger\n",
    "\n",
    "    def _parseActiveSite(self):\n",
    "        data = self._rawdata\n",
    "        active_site = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            \n",
    "            if value.get('type') != \"active site\":\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <feature type=\"active site\" description=\"Proton donor\" evidence=\"2\">\n",
    "                <location>\n",
    "                <position position=\"613\"/>\n",
    "                </location>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            descp = value.get('description')\n",
    "            pos_elem = value.find('up:location/up:position', ns)\n",
    "            pos   = int(pos_elem.attrib.get('position')) if pos_elem is not None else None\n",
    "            active_site.append({\n",
    "                'description': descp, \n",
    "                'position': pos\n",
    "            })\n",
    "        self._active_site = active_site\n",
    "    \n",
    "    def _parseBindingSite(self):\n",
    "        data = self._rawdata\n",
    "        binding_site = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            \n",
    "            if value.get('type') != \"binding site\":\n",
    "                continue\n",
    "            \n",
    "            \"\"\"\n",
    "            <feature type=\"binding site\" evidence=\"7 9 22 23 24\">\n",
    "                <location>\n",
    "                <position position=\"617\"/>\n",
    "                </location>\n",
    "                <ligand>\n",
    "                <name>Zn(2+)</name>\n",
    "                <dbReference type=\"ChEBI\" id=\"CHEBI:29105\"/>\n",
    "                </ligand>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            pos_elem = value.find('up:location/up:position', ns)\n",
    "            pos   = int(pos_elem.attrib.get('position')) if pos_elem is not None else None\n",
    "            \n",
    "            ligand_elem = value.find('up:ligand', ns)\n",
    "            ligand_name = ligand_elem.find('up:name', ns)\n",
    "            ligand_name = ligand_name.text if ligand_name is not None else None\n",
    "            ligand_chebi= ligand_elem.find('up:dbReference[@type=\"ChEBI\"]', ns)\n",
    "            ligand_chebi = ligand_chebi.attrib['id'] if ligand_chebi is not None else None\n",
    "            binding_site.append({\n",
    "                'position': pos, \n",
    "                'name': ligand_name, \n",
    "                'chebi': ligand_chebi\n",
    "            })\n",
    "        self._binding_site = binding_site\n",
    "    \n",
    "    def _parseSite(self):\n",
    "        data = self._rawdata\n",
    "        site = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            \n",
    "            if value.get('type') != \"site\":\n",
    "                continue\n",
    "            \n",
    "            \"\"\"\n",
    "            <feature type=\"site\" description=\"Breakpoint for translocation to form BIRC2-MALT1\">\n",
    "                <location>\n",
    "                    <begin position=\"323\"/>\n",
    "                    <end position=\"324\"/>\n",
    "                </location>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            descp = value.get('description')\n",
    "            begin_elem = value.find('up:location/up:begin', ns)\n",
    "            end_elem = value.find('up:location/up:end', ns)\n",
    "            begin = begin_elem.attrib.get('position') if begin_elem is not None else None\n",
    "            end = end_elem.attrib.get('position') if end_elem is not None else None\n",
    "            site.append({\n",
    "                'description': descp, \n",
    "                'begin': begin, \n",
    "                'end': end\n",
    "            })\n",
    "        self._site = site\n",
    "    \n",
    "    def _parseCofactor(self):\n",
    "        data = self._rawdata\n",
    "        cofactors = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('comment'):\n",
    "                continue\n",
    "            \n",
    "            if type(value) == list:\n",
    "                continue\n",
    "            \n",
    "            if value.get('type') != \"cofactor\":\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <comment type=\"cofactor\">\n",
    "                <cofactor evidence=\"2\">\n",
    "                    <name>cf_name</name>\n",
    "                    <dbReference type=\"ChEBI\" id=cf_chebi/>\n",
    "                </cofactor>\n",
    "            </comment>\n",
    "            \"\"\"\n",
    "            cf_elem = value.find('up:cofactor', ns)\n",
    "            # ---\n",
    "            cf_name = cf_elem.find('up:name', ns)\n",
    "            cf_chebi= cf_elem.find('up:dbReference[@type=\"ChEBI\"]', ns)\n",
    "            cf_chebi = cf_chebi.attrib['id'] if cf_chebi is not None else None\n",
    "            # ---\n",
    "            cofactors.append({\n",
    "                'name': cf_name.text, \n",
    "                'chebi': cf_chebi\n",
    "            })\n",
    "        self._cofactors = cofactors\n",
    "    \n",
    "    def _parseCellLocation(self):\n",
    "        data = self._rawdata\n",
    "        cell_location = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            \n",
    "            type_list = ['topological domain', 'transmembrane region', 'intramembrane region']\n",
    "            loc_type  = value.get('type')\n",
    "            if loc_type not in type_list:\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <feature type=\"intramembrane region\" evidence=\"45\">\n",
    "                <location>\n",
    "                <begin position=\"2\"/>\n",
    "                <end position=\"13\"/>\n",
    "                </location>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            descp = value.get('description')\n",
    "            begin_elem = value.find('up:location/up:begin', ns)\n",
    "            end_elem = value.find('up:location/up:end', ns)\n",
    "            begin = begin_elem.attrib.get('position') if begin_elem is not None else None\n",
    "            end = end_elem.attrib.get('position') if end_elem is not None else None\n",
    "            cell_location.append({\n",
    "                'type': loc_type,\n",
    "                'description': descp, \n",
    "                'begin': begin, \n",
    "                'end': end\n",
    "            })\n",
    "        self._cell_location = cell_location\n",
    "\n",
    "    def _parseSeqAnnotfromPDB(self, pdb_instances):\n",
    "        \"\"\"pdb_instances ['1AID.A', '1AID.B']\n",
    "        \"\"\"\n",
    "        query = Query(\n",
    "            input_type=\"polymer_entity_instances\",\n",
    "            input_ids=pdb_instances,\n",
    "            return_data_list=[\n",
    "                \"polymer_entity_instances.rcsb_id\",\n",
    "                \"rcsb_polymer_instance_feature.type\",\n",
    "                \"rcsb_polymer_instance_feature.feature_positions.beg_seq_id\",\n",
    "                \"rcsb_polymer_instance_feature.feature_positions.end_seq_id\",\n",
    "                \n",
    "                'rcsb_polymer_instance_info.modeled_residue_count',\n",
    "                'rcsb_polymer_instance_feature_summary.coverage',\n",
    "                'rcsb_polymer_instance_feature_summary.type',\n",
    "                'polymer_entity.rcsb_polymer_entity.pdbx_mutation',\n",
    "                'polymer_entity.entity_poly.rcsb_mutation_count',\n",
    "            ]\n",
    "        )\n",
    "        r = query.exec()\n",
    "\n",
    "        out = {}\n",
    "        for entry in r['data']['polymer_entity_instances']:\n",
    "            instance = entry['rcsb_id']\n",
    "            instance_feature = entry.get('rcsb_polymer_instance_feature', None)\n",
    "                \n",
    "            unobs_res = [ele['feature_positions'] for ele in instance_feature if ele['type'] == 'UNOBSERVED_RESIDUE_XYZ']\n",
    "            unobs_atom= [ele['feature_positions'] for ele in instance_feature if ele['type'] == 'UNOBSERVED_ATOM_XYZ']\n",
    "            \n",
    "            # Turn into a list of residues / atoms\n",
    "            unobs_res = [\n",
    "                i for block in unobs_res for r in block\n",
    "                for i in range(r['beg_seq_id'], r['end_seq_id'] + 1)\n",
    "            ]\n",
    "            unobs_atom = [\n",
    "                i for block in unobs_atom for r in block\n",
    "                for i in range(r['beg_seq_id'], r['end_seq_id'] + 1)\n",
    "            ]\n",
    "            \n",
    "            # Extract specific types\n",
    "            coverage_field = entry['rcsb_polymer_instance_feature_summary']    \n",
    "            unobs_res_cov = next((d['coverage'] for d in coverage_field if d['type'] == 'UNOBSERVED_RESIDUE_XYZ'), 0)\n",
    "            unobs_atom_cov = next((d['coverage'] for d in coverage_field if d['type'] == 'UNOBSERVED_ATOM_XYZ'), 0)\n",
    "\n",
    "            coverage = {\n",
    "                \"unobs_res\": unobs_res_cov,\n",
    "                \"unobs_atom\": unobs_atom_cov\n",
    "            }\n",
    "            \n",
    "            modeled_residue_count = entry['rcsb_polymer_instance_info']['modeled_residue_count']\n",
    "            pdbx_mutation = entry['polymer_entity']['rcsb_polymer_entity']['pdbx_mutation']\n",
    "            rcsb_mutation_count = entry['polymer_entity']['entity_poly']['rcsb_mutation_count']\n",
    "            \n",
    "            out[instance] = {\n",
    "                'unobs_res': unobs_res,\n",
    "                'unobs_atom': unobs_atom,\n",
    "                'coverage': coverage,\n",
    "                'modeled_residue_count': modeled_residue_count,\n",
    "                'pdbx_mutation': pdbx_mutation,\n",
    "                'rcsb_mutation_count': rcsb_mutation_count,\n",
    "            }\n",
    "        return out\n",
    "\n",
    "    def _parseLigandsfromPDB(self, pdblist):\n",
    "        query = Query(\n",
    "            input_type=\"entries\",\n",
    "            input_ids=pdblist,\n",
    "            return_data_list=[\n",
    "                \"nonpolymer_entities.pdbx_entity_nonpoly.comp_id\",\n",
    "                \"nonpolymer_entities.pdbx_entity_nonpoly.name\",\n",
    "                \"nonpolymer_entities.rcsb_nonpolymer_entity.pdbx_description\",\n",
    "            ]\n",
    "        )\n",
    "        r = query.exec()\n",
    "        \n",
    "        out = {}\n",
    "        for entry in r['data']['entries']:\n",
    "            pdbid = entry['rcsb_id']\n",
    "            ligand_list = entry.get('nonpolymer_entities', None)\n",
    "            # Return None if no ligand\n",
    "            if ligand_list is None:\n",
    "                out[pdbid] = None\n",
    "                continue\n",
    "            \n",
    "            out[pdbid] = []\n",
    "            for entity in ligand_list:\n",
    "                _dict = {\n",
    "                    'comp_id': entity['pdbx_entity_nonpoly']['comp_id'],\n",
    "                    'name': entity['pdbx_entity_nonpoly']['name'],\n",
    "                    'pdbx_description': entity['rcsb_nonpolymer_entity']['pdbx_description']\n",
    "                }\n",
    "                out[pdbid].append(_dict)\n",
    "        return out\n",
    "\n",
    "    def _parseRvaluefromPDB(self, pdblist):\n",
    "        query = Query(\n",
    "            input_type=\"entries\",\n",
    "            input_ids=pdblist,\n",
    "            return_data_list=[\n",
    "                \"rcsb_accession_info.initial_release_date\",\n",
    "                \"refine.ls_R_factor_R_free\",\n",
    "                \"refine.ls_R_factor_R_work\",\n",
    "                \"refine.ls_R_factor_obs\",\n",
    "                ]\n",
    "        )\n",
    "        r = query.exec()\n",
    "        \n",
    "        out = {}\n",
    "        for entry in r['data']['entries']:\n",
    "            pdbid = entry['rcsb_id']\n",
    "            rcsb_accession_info = entry.get('rcsb_accession_info', None)\n",
    "            # Return None if no ligand\n",
    "            if rcsb_accession_info is None:\n",
    "                initial_release_date = None\n",
    "            else:\n",
    "                initial_release_date = rcsb_accession_info['initial_release_date']\n",
    "                \n",
    "            refine = entry.get('refine', None)\n",
    "            # Return None if no refine\n",
    "            if refine is None:\n",
    "                ls_R_factor_R_free = None\n",
    "                ls_R_factor_R_work = None\n",
    "                ls_R_factor_obs = None\n",
    "            else:\n",
    "                refine_info = refine[0]\n",
    "                ls_R_factor_R_free = refine_info['ls_R_factor_R_free']\n",
    "                ls_R_factor_R_work = refine_info['ls_R_factor_R_work']\n",
    "                ls_R_factor_obs    = refine_info['ls_R_factor_obs']\n",
    "                \n",
    "            out[pdbid] = {\n",
    "                'initial_release_date': initial_release_date,\n",
    "                'ls_R_factor_R_free': ls_R_factor_R_free,\n",
    "                'ls_R_factor_R_work': ls_R_factor_R_work,\n",
    "                'ls_R_factor_obs': ls_R_factor_obs,\n",
    "            }\n",
    "        return out\n",
    "    \n",
    "    def _parsePDB(self):\n",
    "        data = self._rawdata\n",
    "        PDBdata = {}\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('dbReference'):\n",
    "                continue\n",
    "            try:\n",
    "                pdbid = value['PDB']\n",
    "            except (KeyError, TypeError) as e:\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <dbReference type=\"PDB\" id=pdbid>\n",
    "                <property type=\"method\" value=\"EM\"/>\n",
    "                <property type=\"resolution\" value=resolution/>\n",
    "                <property type=\"chains\" value=pdbchains/>\n",
    "    \t\t</dbReference>\n",
    "            \"\"\"\n",
    "            method = value['method']\n",
    "            method = value.get('method', None)\n",
    "            # pdbchains = value['chains'] # e.g. \"B/D/F/G/H/I=1-450\"\n",
    "            pdbchains = value.get('chains', []) # e.g. \"B/D/F/G/H/I=1-450\"\n",
    "            resolution = value.get('resolution', '1.00 A')\n",
    "            resolution = float(resolution.split(' ')[0])\n",
    "            \n",
    "            # example chain strings: \"A=27-139, B=140-150\" or \"A/B=27-150\"\n",
    "            chains = []\n",
    "            resrange = None\n",
    "            try:\n",
    "                pdbchains = comma_splitter(pdbchains)\n",
    "                for chain in pdbchains:\n",
    "                    chids, resrange = chain.split('=')\n",
    "                    chids = [chid.strip() for chid in chids.split('/')]\n",
    "                    for chid in chids:\n",
    "                        chains.append(chid)\n",
    "            except Exception as e:\n",
    "                LOGGER.warn(str(e))\n",
    "                LOGGER.warn('Suspected no chain information')\n",
    "                    \n",
    "            PDBdata[pdbid] = {\n",
    "                'method': method,\n",
    "                'resolution': resolution,\n",
    "                'chains': chains,\n",
    "                'resrange': resrange,\n",
    "            }\n",
    "\n",
    "        pdblist = list(PDBdata.keys())\n",
    "        if len(pdblist) == 0:\n",
    "            self._pdbdata = PDBdata\n",
    "            return\n",
    "        \n",
    "        # RCSB Data API: entries \n",
    "        # Retrieved info: ligands, released date, Observed Residual factor (R-value obs) \n",
    "        ligands = self._parseLigandsfromPDB(pdblist)\n",
    "        rvalues = self._parseRvaluefromPDB(pdblist)\n",
    "        \n",
    "        # fetchAsymIDs to convert auth_asym_ids into label_asym_id\n",
    "        auth2label = self.fetchAsymIDs(pdblist)\n",
    "        \n",
    "        for pdbid in PDBdata:\n",
    "            PDBdata[pdbid]['ligand'] = ligands[pdbid]\n",
    "            PDBdata[pdbid]['initial_release_date'] = rvalues[pdbid]['initial_release_date']\n",
    "            PDBdata[pdbid]['ls_R_factor_R_free'] = rvalues[pdbid]['ls_R_factor_R_free']\n",
    "            PDBdata[pdbid]['ls_R_factor_R_work'] = rvalues[pdbid]['ls_R_factor_R_work']\n",
    "            PDBdata[pdbid]['ls_R_factor_obs'] = rvalues[pdbid]['ls_R_factor_obs']\n",
    "            \n",
    "            # fetchAsymIDs to convert auth_asym_ids into label_asym_id\n",
    "            chains = PDBdata[pdbid]['chains']\n",
    "            chain_dict = auth2label.get(pdbid, None)\n",
    "            if chain_dict is None:\n",
    "                LOGGER.warn(f'fetchAsymIDs: No infor. of {pdbid}')\n",
    "            else:\n",
    "                chains = [chain_dict.get(chid, chid) for chid in chains]\n",
    "            \n",
    "            # RCSB Data API: polymer_entity_instances \n",
    "            # Retrieved info: Sequence Annotations - UNOBSERVED_RESIDUE_XYZ\n",
    "            pdb_instances = [f'{pdbid}.{chid}' for chid in chains]\n",
    "            if len(pdb_instances) > 0:\n",
    "                seq_annot = self._parseSeqAnnotfromPDB(pdb_instances)\n",
    "            else:\n",
    "                seq_annot = None\n",
    "            PDBdata[pdbid]['seq_annot'] = seq_annot\n",
    "        self._pdbdata = PDBdata\n",
    "    \n",
    "    def fetchAsymIDs(self, pdblist):\n",
    "        \"\"\"\n",
    "        Convert auth_asym_ids into label_asym_id. \n",
    "        https://www.rcsb.org/docs/general-help/identifiers-in-pdb#:~:text=type%20of%20entity.-,Macromolecular%20Instance%20ID,R%2C%20while%20the%20PDB%20assigned%20ones%20are%20C%20and%20D%20respectively.,-The%20polymer%20sequences\n",
    "        \n",
    "        Return: dict\n",
    "            given auth_asym_ids, dict can be used as a look up table to find label_asym_id.\n",
    "        \"\"\"\n",
    "        query = Query(\n",
    "            input_type=\"entries\",\n",
    "            input_ids=pdblist,\n",
    "            return_data_list=[\n",
    "                \"polymer_entities.polymer_entity_instances.rcsb_id\",\n",
    "                \"polymer_entities.rcsb_polymer_entity_container_identifiers.auth_asym_ids\",\n",
    "            ]\n",
    "        )\n",
    "        r = query.exec()\n",
    "\n",
    "        if len(r['data']['entries']) == 0:\n",
    "            LOGGER.warn(f'fetchAsymIDs: Check input {pdblist}')\n",
    "            return {}\n",
    "\n",
    "        auth2label = {}\n",
    "        for entry in r['data']['entries']:\n",
    "            pdbid = entry['rcsb_id']\n",
    "            \n",
    "            _dict = {}\n",
    "            for entity in entry['polymer_entities']:\n",
    "                label_asym_id = entity['polymer_entity_instances'][0]['rcsb_id'].split('.')[-1]\n",
    "                auth_asym_id  = entity['rcsb_polymer_entity_container_identifiers']['auth_asym_ids'][0]\n",
    "                _dict[auth_asym_id] = label_asym_id\n",
    "            \n",
    "            auth2label[pdbid] = _dict\n",
    "        return auth2label\n",
    "\n",
    "    def _parse(self):\n",
    "        LOGGER.info(f'Parse UniProt information of {self.getAccession()}...')\n",
    "        LOGGER.timeit('_parse')\n",
    "        self._parseActiveSite()\n",
    "        self._parseBindingSite()\n",
    "        self._parseSite()\n",
    "        self._parseCofactor()\n",
    "        self._parseDNAbinding()\n",
    "        self._parseZincfinger()\n",
    "        self._parseCellLocation()\n",
    "        self._parsePDB()\n",
    "        LOGGER.report(f'Parsing in %.1fs.', '_parse')\n",
    "\n",
    "def searchUniprot(id):\n",
    "    \"\"\"Search Uniprot with *id* and return a :class:`UniprotRecord` containing the results. \n",
    "    \"\"\"\n",
    "    def _queryUniprot(*args, n_attempts=3, dt=1, **kwargs):\n",
    "        \"\"\"\n",
    "        Redefine prody function to check for no internet connection\n",
    "        \"\"\"\n",
    "        attempt = 0\n",
    "        while attempt < n_attempts:\n",
    "            try:\n",
    "                _ = openURL('http://www.uniprot.org/')\n",
    "                break\n",
    "            except:\n",
    "                LOGGER.info(\n",
    "                    f'Attempt {attempt} to contact www.uniprot.org failed')\n",
    "                attempt += 1\n",
    "                time.sleep((attempt+1)*dt)\n",
    "        else:\n",
    "            _ = openURL('http://www.uniprot.org/')\n",
    "        return queryUniprot(*args, **kwargs)\n",
    "\n",
    "    data = _queryUniprot(id)\n",
    "    return UniprotRecord(data)\n",
    "\n",
    "comma_splitter = re.compile(r'\\s*,\\s*').split\n",
    "ns = {'up': 'http://uniprot.org/uniprot'}\n",
    "    \n",
    "class UniprotRecord(object):\n",
    "    \"\"\"This class provides a wrapper for UniProt data including functions \n",
    "    for accessing particular fields and parsing associated PDB entries.\"\"\"\n",
    "    def __init__(self, data):\n",
    "        self._rawdata = data\n",
    "        self._pdbdata = []\n",
    "        self._parse()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<UniprotRecord: %s>'%self.getTitle()\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.getTitle()\n",
    "\n",
    "    def setData(self, value):\n",
    "        self._rawdata = value\n",
    "        self._parse()\n",
    "\n",
    "    def getData(self):\n",
    "        return self._rawdata\n",
    "\n",
    "    def getPDBs(self):\n",
    "        return self._pdbdata\n",
    "    \n",
    "    def getAccession(self, index=0):\n",
    "        \"\"\"accession tag\"\"\"\n",
    "        return self.getEntry('accession', index)\n",
    "    \n",
    "    def getName(self, index=0):\n",
    "        \"\"\"name tag\"\"\"\n",
    "        return self.getEntry('name', index)\n",
    "\n",
    "    def getProtein(self, index=0):\n",
    "        \"\"\"protein tag\n",
    "        <protein>\n",
    "            <recommendedName>\n",
    "                <fullName>Gap junction beta-2 protein</fullName>\n",
    "            </recommendedName>\n",
    "            <alternativeName>\n",
    "                <fullName evidence=\"57 58\">Connexin-26</fullName>\n",
    "                <shortName evidence=\"58\">Cx26</shortName>\n",
    "            </alternativeName>\n",
    "        </protein>\n",
    "        \"\"\"\n",
    "        protein = self.getEntry('protein', index)\n",
    "        \n",
    "        try:\n",
    "            recommend_elem = protein.find('up:recommendedName', ns)\n",
    "            alternative_elem = protein.find('up:recommendedName', ns)\n",
    "            \n",
    "            recommend_name = recommend_elem.find('up:fullName', ns)\n",
    "            alter_fullname = alternative_elem.find('up:fullName', ns)\n",
    "            alter_shortname = alternative_elem.find('up:shortName', ns)\n",
    "            \n",
    "            recommend_name = recommend_name.text if recommend_name is not None else None\n",
    "            alter_fullname = alter_fullname.text if alter_fullname is not None else None\n",
    "            alter_shortname = alter_shortname.text if alter_shortname is not None else None\n",
    "        except:\n",
    "            submitted_name = protein.find('up:submittedName/up:fullName', ns)\n",
    "            submitted_name = submitted_name.text if submitted_name is not None else None\n",
    "            recommend_name = submitted_name\n",
    "            alter_fullname = None\n",
    "            alter_shortname = None\n",
    "        \n",
    "        return {\n",
    "            'recommend_name': recommend_name,\n",
    "            'alter_fullname': alter_fullname,\n",
    "            'alter_shortname': alter_shortname            \n",
    "        }\n",
    "        \n",
    "    def getGene(self, index=0):\n",
    "        \"\"\"gene tag\n",
    "        <gene>\n",
    "            <name type=\"primary\">GJB2</name>\n",
    "        </gene>\n",
    "        \"\"\"\n",
    "        try:\n",
    "            gene = self.getEntry('gene', index)\n",
    "            name_elem = gene.find('up:name[@type=\"primary\"]', ns)\n",
    "            return name_elem.text if name_elem is not None else None\n",
    "        \n",
    "        except Exception as e:\n",
    "            LOGGER.warn(f'Error while parsing {id}: {e} -> None')\n",
    "            return None\n",
    "\n",
    "    def getOrganism(self, index=0):\n",
    "        \"\"\"organism tag\n",
    "        <organism>\n",
    "            <name type=\"scientific\">Homo sapiens</name>\n",
    "            <name type=\"common\">Human</name>\n",
    "            <dbReference type=\"NCBI Taxonomy\" id=\"9606\"/>\n",
    "            <lineage>\n",
    "                <taxon>Eukaryota</taxon>\n",
    "                <taxon>Metazoa</taxon>\n",
    "                <taxon>Chordata</taxon>\n",
    "                <taxon>Craniata</taxon>\n",
    "                <taxon>Vertebrata</taxon>\n",
    "                <taxon>Euteleostomi</taxon>\n",
    "                <taxon>Mammalia</taxon>\n",
    "                <taxon>Eutheria</taxon>\n",
    "                <taxon>Euarchontoglires</taxon>\n",
    "                <taxon>Primates</taxon>\n",
    "                <taxon>Haplorrhini</taxon>\n",
    "                <taxon>Catarrhini</taxon>\n",
    "                <taxon>Hominidae</taxon>\n",
    "                <taxon>Homo</taxon>\n",
    "            </lineage>\n",
    "        </organism>\n",
    "        \"\"\"\n",
    "        organism = self.getEntry('organism', index)\n",
    "\n",
    "        sci_name = organism.find('up:name[@type=\"scientific\"]', ns)\n",
    "        com_name = organism.find('up:name[@type=\"common\"]', ns)\n",
    "        db_ref = organism.find('up:dbReference[@type=\"NCBI Taxonomy\"]', ns)\n",
    "        lineage_tags = organism.findall('up:lineage/up:taxon', ns)\n",
    "\n",
    "        return {\n",
    "            'scientific_name': sci_name.text.strip() if sci_name is not None else None,\n",
    "            'common_name': com_name.text.strip() if com_name is not None else None,\n",
    "            'taxonomy_id': db_ref.attrib['id'] if db_ref is not None else None,\n",
    "            'lineage': [taxon.text.strip() for taxon in lineage_tags if taxon.text]\n",
    "        }\n",
    "        \n",
    "    def getCellLocation(self):\n",
    "        return self._cell_location\n",
    "        \n",
    "    def getReference(self, index=0):\n",
    "        \"\"\"reference tag\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def getComment(self, index=0):\n",
    "        \"\"\"conmment tag\"\"\"\n",
    "        pass\n",
    "        \n",
    "    def getDBreference(self, index=0):\n",
    "        \"\"\"dbReference tag\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def getProteinExistence(self, index=0):\n",
    "        \"\"\"proteinExistence tag\"\"\"\n",
    "        pass\n",
    "     \n",
    "    def getKeyword(self, index=0):\n",
    "        \"\"\"keyword tag\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def getFeature(self, index=0):\n",
    "        \"\"\"feature tag\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def getEvidence(self, index=0):\n",
    "        \"\"\"evidence tag\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def getSequence(self, index=0):\n",
    "        return self.getEntry('sequence', index)\n",
    "    \n",
    "    def getZincFinger(self):\n",
    "        return self._zinc_finger\n",
    "    \n",
    "    def getDNAbinding(self):\n",
    "        return self._dna_binding\n",
    "    \n",
    "    def getActivateSite(self):\n",
    "        return self._active_site\n",
    "    \n",
    "    def getBindingSite(self):\n",
    "        return self._binding_site\n",
    "    \n",
    "    def getSite(self):\n",
    "        return self._site\n",
    "    \n",
    "    def getAlphaFold(self):\n",
    "        \"\"\"<dbReference type=\"AlphaFoldDB\" id=\"Q9UDY8\"/>\"\"\"\n",
    "        AlphaFoldDB = None\n",
    "        for key, value in self._rawdata.items():\n",
    "            if not key.startswith('dbReference'):\n",
    "                continue\n",
    "\n",
    "            if type(value) != list or len(value) != 2:\n",
    "                continue\n",
    "            \n",
    "            # [('type', 'AlphaFoldDB'), ('id', 'Q13509')]\n",
    "            if value[0][1] == 'AlphaFoldDB':\n",
    "                AlphaFoldDB = value[1][1]\n",
    "                break\n",
    "        return AlphaFoldDB\n",
    "    \n",
    "    def getCofactor(self):\n",
    "        return self._cofactors\n",
    "    \n",
    "    def getTitle(self):\n",
    "        uid = self.getAccession()\n",
    "        name = self.getName()\n",
    "        return '%s (%s)'%(uid, name)\n",
    "\n",
    "    def getEntry(self, item, index=0):\n",
    "        key = '%s%4d'%(item, index)\n",
    "        if key in self._rawdata:\n",
    "            return self._rawdata[key]\n",
    "        else:\n",
    "            raise KeyError('%s does not exist in the Uniprot record'%key)\n",
    "\n",
    "    def _parseDNAbinding(self):\n",
    "        data = self._rawdata\n",
    "        dna_binding = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            if value.get('type') != \"DNA-binding region\":\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <feature type=\"DNA-binding region\" description=\"HMG box 1\" evidence=\"4\">\n",
    "                <location>\n",
    "                <begin position=\"9\"/>\n",
    "                <end position=\"79\"/>\n",
    "                </location>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            descp = value.get('description')\n",
    "            begin_elem = value.find('up:location/up:begin', ns)\n",
    "            end_elem = value.find('up:location/up:end', ns)\n",
    "            begin = begin_elem.attrib.get('position') if begin_elem is not None else None\n",
    "            end = end_elem.attrib.get('position') if end_elem is not None else None\n",
    "            dna_binding.append({\n",
    "                'description': descp, \n",
    "                'begin': begin, \n",
    "                'end': end\n",
    "            })\n",
    "        self._dna_binding = dna_binding\n",
    "            \n",
    "    def _parseZincfinger(self):\n",
    "        data = self._rawdata\n",
    "        zinc_finger = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            if value.get('type') != \"zinc finger region\":\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <feature type=\"zinc finger region\" description=\"C2H2-type 1\" evidence=\"1\">\n",
    "                <location>\n",
    "                <begin position=\"110\"/>\n",
    "                <end position=\"133\"/>\n",
    "                </location>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            descp = value.get('description')\n",
    "            begin_elem = value.find('up:location/up:begin', ns)\n",
    "            end_elem = value.find('up:location/up:end', ns)\n",
    "            begin = begin_elem.attrib.get('position') if begin_elem is not None else None\n",
    "            end = end_elem.attrib.get('position') if end_elem is not None else None\n",
    "            zinc_finger.append({\n",
    "                'description': descp, \n",
    "                'begin': begin, \n",
    "                'end': end\n",
    "            })\n",
    "        self._zinc_finger = zinc_finger\n",
    "\n",
    "    def _parseActiveSite(self):\n",
    "        data = self._rawdata\n",
    "        active_site = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            \n",
    "            if value.get('type') != \"active site\":\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <feature type=\"active site\" description=\"Proton donor\" evidence=\"2\">\n",
    "                <location>\n",
    "                <position position=\"613\"/>\n",
    "                </location>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            descp = value.get('description')\n",
    "            pos_elem = value.find('up:location/up:position', ns)\n",
    "            pos   = int(pos_elem.attrib.get('position')) if pos_elem is not None else None\n",
    "            active_site.append({\n",
    "                'description': descp, \n",
    "                'position': pos\n",
    "            })\n",
    "        self._active_site = active_site\n",
    "    \n",
    "    def _parseBindingSite(self):\n",
    "        data = self._rawdata\n",
    "        binding_site = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            \n",
    "            if value.get('type') != \"binding site\":\n",
    "                continue\n",
    "            \n",
    "            \"\"\"\n",
    "            <feature type=\"binding site\" evidence=\"7 9 22 23 24\">\n",
    "                <location>\n",
    "                <position position=\"617\"/>\n",
    "                </location>\n",
    "                <ligand>\n",
    "                <name>Zn(2+)</name>\n",
    "                <dbReference type=\"ChEBI\" id=\"CHEBI:29105\"/>\n",
    "                </ligand>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            pos_elem = value.find('up:location/up:position', ns)\n",
    "            pos   = int(pos_elem.attrib.get('position')) if pos_elem is not None else None\n",
    "            \n",
    "            ligand_elem = value.find('up:ligand', ns)\n",
    "            ligand_name = ligand_elem.find('up:name', ns)\n",
    "            ligand_name = ligand_name.text if ligand_name is not None else None\n",
    "            ligand_chebi= ligand_elem.find('up:dbReference[@type=\"ChEBI\"]', ns)\n",
    "            ligand_chebi = ligand_chebi.attrib['id'] if ligand_chebi is not None else None\n",
    "            binding_site.append({\n",
    "                'position': pos, \n",
    "                'name': ligand_name, \n",
    "                'chebi': ligand_chebi\n",
    "            })\n",
    "        self._binding_site = binding_site\n",
    "    \n",
    "    def _parseSite(self):\n",
    "        data = self._rawdata\n",
    "        site = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            \n",
    "            if value.get('type') != \"site\":\n",
    "                continue\n",
    "            \n",
    "            \"\"\"\n",
    "            <feature type=\"site\" description=\"Breakpoint for translocation to form BIRC2-MALT1\">\n",
    "                <location>\n",
    "                    <begin position=\"323\"/>\n",
    "                    <end position=\"324\"/>\n",
    "                </location>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            descp = value.get('description')\n",
    "            begin_elem = value.find('up:location/up:begin', ns)\n",
    "            end_elem = value.find('up:location/up:end', ns)\n",
    "            begin = begin_elem.attrib.get('position') if begin_elem is not None else None\n",
    "            end = end_elem.attrib.get('position') if end_elem is not None else None\n",
    "            site.append({\n",
    "                'description': descp, \n",
    "                'begin': begin, \n",
    "                'end': end\n",
    "            })\n",
    "        self._site = site\n",
    "    \n",
    "    def _parseCofactor(self):\n",
    "        data = self._rawdata\n",
    "        cofactors = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('comment'):\n",
    "                continue\n",
    "            \n",
    "            if type(value) == list:\n",
    "                continue\n",
    "            \n",
    "            if value.get('type') != \"cofactor\":\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <comment type=\"cofactor\">\n",
    "                <cofactor evidence=\"2\">\n",
    "                    <name>cf_name</name>\n",
    "                    <dbReference type=\"ChEBI\" id=cf_chebi/>\n",
    "                </cofactor>\n",
    "            </comment>\n",
    "            \"\"\"\n",
    "            cf_elem = value.find('up:cofactor', ns)\n",
    "            # ---\n",
    "            cf_name = cf_elem.find('up:name', ns)\n",
    "            cf_chebi= cf_elem.find('up:dbReference[@type=\"ChEBI\"]', ns)\n",
    "            cf_chebi = cf_chebi.attrib['id'] if cf_chebi is not None else None\n",
    "            # ---\n",
    "            cofactors.append({\n",
    "                'name': cf_name.text, \n",
    "                'chebi': cf_chebi\n",
    "            })\n",
    "        self._cofactors = cofactors\n",
    "    \n",
    "    def _parseCellLocation(self):\n",
    "        data = self._rawdata\n",
    "        cell_location = []\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('feature'):\n",
    "                continue\n",
    "            \n",
    "            type_list = ['topological domain', 'transmembrane region', 'intramembrane region']\n",
    "            loc_type  = value.get('type')\n",
    "            if loc_type not in type_list:\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <feature type=\"intramembrane region\" evidence=\"45\">\n",
    "                <location>\n",
    "                <begin position=\"2\"/>\n",
    "                <end position=\"13\"/>\n",
    "                </location>\n",
    "            </feature>\n",
    "            \"\"\"\n",
    "            descp = value.get('description')\n",
    "            begin_elem = value.find('up:location/up:begin', ns)\n",
    "            end_elem = value.find('up:location/up:end', ns)\n",
    "            begin = begin_elem.attrib.get('position') if begin_elem is not None else None\n",
    "            end = end_elem.attrib.get('position') if end_elem is not None else None\n",
    "            cell_location.append({\n",
    "                'type': loc_type,\n",
    "                'description': descp, \n",
    "                'begin': begin, \n",
    "                'end': end\n",
    "            })\n",
    "        self._cell_location = cell_location\n",
    "\n",
    "    def _parseSeqAnnotfromPDB(self, pdb_instances):\n",
    "        \"\"\"pdb_instances ['1AID.A', '1AID.B']\n",
    "        \"\"\"\n",
    "        query = Query(\n",
    "            input_type=\"polymer_entity_instances\",\n",
    "            input_ids=pdb_instances,\n",
    "            return_data_list=[\n",
    "                \"polymer_entity_instances.rcsb_id\",\n",
    "                \"rcsb_polymer_instance_feature.type\",\n",
    "                \"rcsb_polymer_instance_feature.feature_positions.beg_seq_id\",\n",
    "                \"rcsb_polymer_instance_feature.feature_positions.end_seq_id\",\n",
    "                \n",
    "                'rcsb_polymer_instance_info.modeled_residue_count',\n",
    "                'rcsb_polymer_instance_feature_summary.coverage',\n",
    "                'rcsb_polymer_instance_feature_summary.type',\n",
    "                'polymer_entity.rcsb_polymer_entity.pdbx_mutation',\n",
    "                'polymer_entity.entity_poly.rcsb_mutation_count',\n",
    "            ]\n",
    "        )\n",
    "        r = query.exec()\n",
    "\n",
    "        out = {}\n",
    "        for entry in r['data']['polymer_entity_instances']:\n",
    "            instance = entry['rcsb_id']\n",
    "            instance_feature = entry.get('rcsb_polymer_instance_feature', None)\n",
    "                \n",
    "            unobs_res = [ele['feature_positions'] for ele in instance_feature if ele['type'] == 'UNOBSERVED_RESIDUE_XYZ']\n",
    "            unobs_atom= [ele['feature_positions'] for ele in instance_feature if ele['type'] == 'UNOBSERVED_ATOM_XYZ']\n",
    "            \n",
    "            # Turn into a list of residues / atoms\n",
    "            unobs_res = [\n",
    "                i for block in unobs_res for r in block\n",
    "                for i in range(r['beg_seq_id'], r['end_seq_id'] + 1)\n",
    "            ]\n",
    "            unobs_atom = [\n",
    "                i for block in unobs_atom for r in block\n",
    "                for i in range(r['beg_seq_id'], r['end_seq_id'] + 1)\n",
    "            ]\n",
    "            \n",
    "            # Extract specific types\n",
    "            coverage_field = entry['rcsb_polymer_instance_feature_summary']    \n",
    "            unobs_res_cov = next((d['coverage'] for d in coverage_field if d['type'] == 'UNOBSERVED_RESIDUE_XYZ'), 0)\n",
    "            unobs_atom_cov = next((d['coverage'] for d in coverage_field if d['type'] == 'UNOBSERVED_ATOM_XYZ'), 0)\n",
    "\n",
    "            coverage = {\n",
    "                \"unobs_res\": unobs_res_cov,\n",
    "                \"unobs_atom\": unobs_atom_cov\n",
    "            }\n",
    "            \n",
    "            modeled_residue_count = entry['rcsb_polymer_instance_info']['modeled_residue_count']\n",
    "            pdbx_mutation = entry['polymer_entity']['rcsb_polymer_entity']['pdbx_mutation']\n",
    "            rcsb_mutation_count = entry['polymer_entity']['entity_poly']['rcsb_mutation_count']\n",
    "            \n",
    "            out[instance] = {\n",
    "                'unobs_res': unobs_res,\n",
    "                'unobs_atom': unobs_atom,\n",
    "                'coverage': coverage,\n",
    "                'modeled_residue_count': modeled_residue_count,\n",
    "                'pdbx_mutation': pdbx_mutation,\n",
    "                'rcsb_mutation_count': rcsb_mutation_count,\n",
    "            }\n",
    "        \n",
    "        if len(out) == 0:\n",
    "            LOGGER.warn(f'_parseSeqAnnotfromPDB: No output for {pdb_instances}')\n",
    "        return out\n",
    "\n",
    "    def _parseLigandsfromPDB(self, pdblist):\n",
    "        query = Query(\n",
    "            input_type=\"entries\",\n",
    "            input_ids=pdblist,\n",
    "            return_data_list=[\n",
    "                \"nonpolymer_entities.pdbx_entity_nonpoly.comp_id\",\n",
    "                \"nonpolymer_entities.pdbx_entity_nonpoly.name\",\n",
    "                \"nonpolymer_entities.rcsb_nonpolymer_entity.pdbx_description\",\n",
    "            ]\n",
    "        )\n",
    "        r = query.exec()\n",
    "        \n",
    "        out = {}\n",
    "        for entry in r['data']['entries']:\n",
    "            pdbid = entry['rcsb_id']\n",
    "            ligand_list = entry.get('nonpolymer_entities', None)\n",
    "            # Return None if no ligand\n",
    "            if ligand_list is None:\n",
    "                out[pdbid] = None\n",
    "                continue\n",
    "            \n",
    "            out[pdbid] = []\n",
    "            for entity in ligand_list:\n",
    "                _dict = {\n",
    "                    'comp_id': entity['pdbx_entity_nonpoly']['comp_id'],\n",
    "                    'name': entity['pdbx_entity_nonpoly']['name'],\n",
    "                    'pdbx_description': entity['rcsb_nonpolymer_entity']['pdbx_description']\n",
    "                }\n",
    "                out[pdbid].append(_dict)\n",
    "        return out\n",
    "\n",
    "    def _parseRvaluefromPDB(self, pdblist):\n",
    "        query = Query(\n",
    "            input_type=\"entries\",\n",
    "            input_ids=pdblist,\n",
    "            return_data_list=[\n",
    "                \"rcsb_accession_info.initial_release_date\",\n",
    "                \"refine.ls_R_factor_R_free\",\n",
    "                \"refine.ls_R_factor_R_work\",\n",
    "                \"refine.ls_R_factor_obs\",\n",
    "                ]\n",
    "        )\n",
    "        r = query.exec()\n",
    "        \n",
    "        out = {}\n",
    "        for entry in r['data']['entries']:\n",
    "            pdbid = entry['rcsb_id']\n",
    "            rcsb_accession_info = entry.get('rcsb_accession_info', None)\n",
    "            # Return None if no ligand\n",
    "            if rcsb_accession_info is None:\n",
    "                initial_release_date = None\n",
    "            else:\n",
    "                initial_release_date = rcsb_accession_info['initial_release_date']\n",
    "                \n",
    "            refine = entry.get('refine', None)\n",
    "            # Return None if no refine\n",
    "            if refine is None:\n",
    "                ls_R_factor_R_free = None\n",
    "                ls_R_factor_R_work = None\n",
    "                ls_R_factor_obs = None\n",
    "            else:\n",
    "                refine_info = refine[0]\n",
    "                ls_R_factor_R_free = refine_info['ls_R_factor_R_free']\n",
    "                ls_R_factor_R_work = refine_info['ls_R_factor_R_work']\n",
    "                ls_R_factor_obs    = refine_info['ls_R_factor_obs']\n",
    "                \n",
    "            out[pdbid] = {\n",
    "                'initial_release_date': initial_release_date,\n",
    "                'ls_R_factor_R_free': ls_R_factor_R_free,\n",
    "                'ls_R_factor_R_work': ls_R_factor_R_work,\n",
    "                'ls_R_factor_obs': ls_R_factor_obs,\n",
    "            }\n",
    "        return out\n",
    "    \n",
    "    def _parsePDB(self):\n",
    "        data = self._rawdata\n",
    "        PDBdata = {}\n",
    "        for key, value in data.items():\n",
    "            if not key.startswith('dbReference'):\n",
    "                continue\n",
    "            try:\n",
    "                pdbid = value['PDB']\n",
    "            except (KeyError, TypeError) as e:\n",
    "                continue\n",
    "            \"\"\"\n",
    "            <dbReference type=\"PDB\" id=pdbid>\n",
    "                <property type=\"method\" value=\"EM\"/>\n",
    "                <property type=\"resolution\" value=resolution/>\n",
    "                <property type=\"chains\" value=pdbchains/>\n",
    "    \t\t</dbReference>\n",
    "            \"\"\"\n",
    "            method = value['method']\n",
    "            method = value.get('method', None)\n",
    "            # pdbchains = value['chains'] # e.g. \"B/D/F/G/H/I=1-450\"\n",
    "            pdbchains = value.get('chains', []) # e.g. \"B/D/F/G/H/I=1-450\"\n",
    "            resolution = value.get('resolution', '1.00 A')\n",
    "            resolution = float(resolution.split(' ')[0])\n",
    "            \n",
    "            # example chain strings: \"A=27-139, B=140-150\" or \"A/B=27-150\"\n",
    "            chains = []\n",
    "            resrange = None\n",
    "            try:\n",
    "                pdbchains = comma_splitter(pdbchains)\n",
    "                for chain in pdbchains:\n",
    "                    chids, resrange = chain.split('=')\n",
    "                    chids = [chid.strip() for chid in chids.split('/')]\n",
    "                    for chid in chids:\n",
    "                        chains.append(chid)\n",
    "            except Exception as e:\n",
    "                LOGGER.warn(str(e))\n",
    "                LOGGER.warn('Suspected no chain information')\n",
    "                    \n",
    "            PDBdata[pdbid] = {\n",
    "                'method': method,\n",
    "                'resolution': resolution,\n",
    "                'chains': chains,\n",
    "                'resrange': resrange,\n",
    "            }\n",
    "\n",
    "        pdblist = list(PDBdata.keys())\n",
    "        if len(pdblist) == 0:\n",
    "            self._pdbdata = PDBdata\n",
    "            return\n",
    "        \n",
    "        # RCSB Data API: entries \n",
    "        # Retrieved info: ligands, released date, Observed Residual factor (R-value obs) \n",
    "        ligands = self._parseLigandsfromPDB(pdblist)\n",
    "        rvalues = self._parseRvaluefromPDB(pdblist)\n",
    "        \n",
    "        # fetchAsymIDs to convert auth_asym_ids into label_asym_id\n",
    "        auth2label = self.fetchAsymIDs(pdblist)\n",
    "        \n",
    "        for pdbid in PDBdata:\n",
    "            PDBdata[pdbid]['ligand'] = ligands[pdbid]\n",
    "            PDBdata[pdbid]['initial_release_date'] = rvalues[pdbid]['initial_release_date']\n",
    "            PDBdata[pdbid]['ls_R_factor_R_free'] = rvalues[pdbid]['ls_R_factor_R_free']\n",
    "            PDBdata[pdbid]['ls_R_factor_R_work'] = rvalues[pdbid]['ls_R_factor_R_work']\n",
    "            PDBdata[pdbid]['ls_R_factor_obs'] = rvalues[pdbid]['ls_R_factor_obs']\n",
    "            \n",
    "            # fetchAsymIDs to convert auth_asym_ids into label_asym_id\n",
    "            chains = PDBdata[pdbid]['chains']\n",
    "            chain_dict = auth2label.get(pdbid, None)\n",
    "            if chain_dict is None:\n",
    "                LOGGER.warn(f'fetchAsymIDs: No infor. of {pdbid}')\n",
    "            else:\n",
    "                chains = [chain_dict.get(chid, chid) for chid in chains]\n",
    "            \n",
    "            # RCSB Data API: polymer_entity_instances \n",
    "            # Retrieved info: Sequence Annotations - UNOBSERVED_RESIDUE_XYZ\n",
    "            pdb_instances = [f'{pdbid}.{chid}' for chid in chains]\n",
    "            print(pdb_instances)\n",
    "            if len(pdb_instances) > 0:\n",
    "                seq_annot = self._parseSeqAnnotfromPDB(pdb_instances)\n",
    "            else:\n",
    "                \n",
    "                seq_annot = None\n",
    "            PDBdata[pdbid]['seq_annot'] = seq_annot\n",
    "        self._pdbdata = PDBdata\n",
    "    \n",
    "    def fetchAsymIDs(self, pdblist):\n",
    "        \"\"\"\n",
    "        Convert auth_asym_ids into label_asym_id. \n",
    "        https://www.rcsb.org/docs/general-help/identifiers-in-pdb#:~:text=type%20of%20entity.-,Macromolecular%20Instance%20ID,R%2C%20while%20the%20PDB%20assigned%20ones%20are%20C%20and%20D%20respectively.,-The%20polymer%20sequences\n",
    "        \n",
    "        Return: dict\n",
    "            given auth_asym_ids, dict can be used as a look up table to find label_asym_id.\n",
    "        \"\"\"\n",
    "        print(pdblist)\n",
    "        query = Query(\n",
    "            input_type=\"entries\",\n",
    "            input_ids=pdblist,\n",
    "            return_data_list=[\n",
    "                \"polymer_entities.polymer_entity_instances.rcsb_id\",\n",
    "                \"polymer_entities.rcsb_polymer_entity_container_identifiers.auth_asym_ids\",\n",
    "            ]\n",
    "        )\n",
    "        r = query.exec()\n",
    "\n",
    "        if len(r['data']['entries']) == 0:\n",
    "            LOGGER.warn(f'fetchAsymIDs: Check input {pdblist}')\n",
    "            return {}\n",
    "\n",
    "        auth2label = {}\n",
    "        for entry in r['data']['entries']:\n",
    "            pdbid = entry['rcsb_id']\n",
    "            \n",
    "            _dict = {}\n",
    "            for entity in entry['polymer_entities']:\n",
    "                label_asym_id = entity['polymer_entity_instances'][0]['rcsb_id'].split('.')[-1]\n",
    "                auth_asym_id  = entity['rcsb_polymer_entity_container_identifiers']['auth_asym_ids'][0]\n",
    "                _dict[auth_asym_id] = label_asym_id\n",
    "            \n",
    "            auth2label[pdbid] = _dict\n",
    "        return auth2label\n",
    "\n",
    "    def _parse(self):\n",
    "        LOGGER.info(f'Parse UniProt information of {self.getAccession()}...')\n",
    "        LOGGER.timeit('_parse')\n",
    "        self._parseActiveSite()\n",
    "        self._parseBindingSite()\n",
    "        self._parseSite()\n",
    "        self._parseCofactor()\n",
    "        self._parseDNAbinding()\n",
    "        self._parseZincfinger()\n",
    "        self._parseCellLocation()\n",
    "        self._parsePDB()\n",
    "        LOGGER.report(f'Parsing in %.1fs.', '_parse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cd3849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "data_json = 'data/parseUniprot_881.json' \n",
    "# 874 UniProt \n",
    "# Plus P0A7V8, P0A7X3\n",
    "# A2VLV3 E1FVX6 E1G1C3 A0A0D9MXW1\n",
    "\n",
    "# {'P63231'}\n",
    "with open(data_json, \"r\") as f:\n",
    "    data_json = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "543d1f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2JLE': {'method': 'X-ray',\n",
       "  'resolution': 2.9,\n",
       "  'chains': ['A', 'B'],\n",
       "  'resrange': '1-566',\n",
       "  'ligand': [{'comp_id': 'I15',\n",
       "    'name': '5-[(5-fluoro-3-methyl-1H-indazol-4-yl)oxy]benzene-1,3-dicarbonitrile',\n",
       "    'pdbx_description': '5-[(5-fluoro-3-methyl-1H-indazol-4-yl)oxy]benzene-1,3-dicarbonitrile'}],\n",
       "  'initial_release_date': '2009-08-04T00:00:00Z',\n",
       "  'ls_R_factor_R_free': 0.3512,\n",
       "  'ls_R_factor_R_work': 0.2613,\n",
       "  'ls_R_factor_obs': 0.2674,\n",
       "  'seq_annot': {'2JLE.A': {'unobs_res': [546,\n",
       "     547,\n",
       "     548,\n",
       "     549,\n",
       "     550,\n",
       "     551,\n",
       "     552,\n",
       "     553,\n",
       "     554,\n",
       "     555,\n",
       "     556,\n",
       "     557,\n",
       "     558,\n",
       "     559,\n",
       "     560,\n",
       "     561,\n",
       "     562,\n",
       "     563,\n",
       "     564,\n",
       "     565,\n",
       "     566],\n",
       "    'unobs_atom': [],\n",
       "    'coverage': {'unobs_res': 0.0371, 'unobs_atom': 0},\n",
       "    'modeled_residue_count': 545,\n",
       "    'pdbx_mutation': None,\n",
       "    'rcsb_mutation_count': 0},\n",
       "   '2JLE.B': {'unobs_res': [1,\n",
       "     2,\n",
       "     218,\n",
       "     219,\n",
       "     220,\n",
       "     221,\n",
       "     222,\n",
       "     223,\n",
       "     224,\n",
       "     225,\n",
       "     226,\n",
       "     227,\n",
       "     228,\n",
       "     229,\n",
       "     431,\n",
       "     432,\n",
       "     433,\n",
       "     434,\n",
       "     435,\n",
       "     436,\n",
       "     437,\n",
       "     438,\n",
       "     439,\n",
       "     440,\n",
       "     441,\n",
       "     442,\n",
       "     443,\n",
       "     444,\n",
       "     445,\n",
       "     446,\n",
       "     447,\n",
       "     448,\n",
       "     449,\n",
       "     450,\n",
       "     451,\n",
       "     452,\n",
       "     453,\n",
       "     454,\n",
       "     455,\n",
       "     456,\n",
       "     457,\n",
       "     458,\n",
       "     459,\n",
       "     460,\n",
       "     461,\n",
       "     462,\n",
       "     463,\n",
       "     464,\n",
       "     465,\n",
       "     466,\n",
       "     467,\n",
       "     468,\n",
       "     469,\n",
       "     470,\n",
       "     471,\n",
       "     472,\n",
       "     473,\n",
       "     474,\n",
       "     475,\n",
       "     476,\n",
       "     477,\n",
       "     478,\n",
       "     479,\n",
       "     480,\n",
       "     481,\n",
       "     482,\n",
       "     483,\n",
       "     484,\n",
       "     485,\n",
       "     486,\n",
       "     487,\n",
       "     488,\n",
       "     489,\n",
       "     490,\n",
       "     491,\n",
       "     492,\n",
       "     493,\n",
       "     494,\n",
       "     495,\n",
       "     496,\n",
       "     497,\n",
       "     498,\n",
       "     499,\n",
       "     500,\n",
       "     501,\n",
       "     502,\n",
       "     503,\n",
       "     504,\n",
       "     505,\n",
       "     506,\n",
       "     507,\n",
       "     508,\n",
       "     509,\n",
       "     510,\n",
       "     511,\n",
       "     512,\n",
       "     513,\n",
       "     514,\n",
       "     515,\n",
       "     516,\n",
       "     517,\n",
       "     518,\n",
       "     519,\n",
       "     520,\n",
       "     521,\n",
       "     522,\n",
       "     523,\n",
       "     524,\n",
       "     525,\n",
       "     526,\n",
       "     527,\n",
       "     528,\n",
       "     529,\n",
       "     530,\n",
       "     531,\n",
       "     532,\n",
       "     533,\n",
       "     534,\n",
       "     535,\n",
       "     536,\n",
       "     537,\n",
       "     538,\n",
       "     539,\n",
       "     540,\n",
       "     541,\n",
       "     542,\n",
       "     543,\n",
       "     544,\n",
       "     545,\n",
       "     546,\n",
       "     547,\n",
       "     548,\n",
       "     549,\n",
       "     550,\n",
       "     551,\n",
       "     552,\n",
       "     553,\n",
       "     554,\n",
       "     555,\n",
       "     556,\n",
       "     557,\n",
       "     558,\n",
       "     559,\n",
       "     560,\n",
       "     561,\n",
       "     562,\n",
       "     563,\n",
       "     564,\n",
       "     565,\n",
       "     566],\n",
       "    'unobs_atom': [230, 232, 430],\n",
       "    'coverage': {'unobs_res': 0.26502, 'unobs_atom': 0.0053},\n",
       "    'modeled_residue_count': 416,\n",
       "    'pdbx_mutation': None,\n",
       "    'rcsb_mutation_count': 0}}},\n",
       " '3HYF': {'method': 'X-ray',\n",
       "  'resolution': 1.7,\n",
       "  'chains': ['A', 'A'],\n",
       "  'resrange': '518-561',\n",
       "  'ligand': [{'comp_id': 'GOL',\n",
       "    'name': 'GLYCEROL',\n",
       "    'pdbx_description': 'GLYCEROL'},\n",
       "   {'comp_id': 'MN',\n",
       "    'name': 'MANGANESE (II) ION',\n",
       "    'pdbx_description': 'MANGANESE (II) ION'},\n",
       "   {'comp_id': 'ACT',\n",
       "    'name': 'ACETATE ION',\n",
       "    'pdbx_description': 'ACETATE ION'},\n",
       "   {'comp_id': 'ON1',\n",
       "    'name': '2-(3,4-dichlorobenzyl)-5,6-dihydroxypyrimidine-4-carboxylic acid',\n",
       "    'pdbx_description': '2-(3,4-dichlorobenzyl)-5,6-dihydroxypyrimidine-4-carboxylic acid'}],\n",
       "  'initial_release_date': '2009-10-20T00:00:00Z',\n",
       "  'ls_R_factor_R_free': 0.232,\n",
       "  'ls_R_factor_R_work': 0.196,\n",
       "  'ls_R_factor_obs': 0.198,\n",
       "  'seq_annot': {'3HYF.A': {'unobs_res': [94, 95, 96, 97, 98, 99, 150],\n",
       "    'unobs_atom': [],\n",
       "    'coverage': {'unobs_res': 0.04667, 'unobs_atom': 0},\n",
       "    'modeled_residue_count': 143,\n",
       "    'pdbx_mutation': None,\n",
       "    'rcsb_mutation_count': 0}}}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json[0]['pdb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aef415d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A0A0D9MXW1', 'A2VLV3', 'E1FVX6', 'E1G1C3', 'P0A7V8', 'P0A7X3', 'P63231'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "uniprotid = 'data/uniprotid.csv'\n",
    "df = pd.read_csv(uniprotid)\n",
    "uniprotid = df.id.to_list()\n",
    "set(uniprotid) - set(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc52529d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@> Parse UniProt information of P0A7V8...\n",
      "2025-08-09 01:30:57,763 [INFO]-logger.info: Parse UniProt information of P0A7V8...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1EG0', '2YKR', '3J9Y', '3J9Z', '3JA1', '3JBU', '3JBV', '3JCD', '3JCE', '3JCJ', '3JCN', '4A2I', '4ADV', '4U1U', '4U1V', '4U20', '4U24', '4U25', '4U26', '4U27', '4V47', '4V48', '4V4H', '4V4Q', '4V4V', '4V4W', '4V50', '4V52', '4V53', '4V54', '4V55', '4V56', '4V57', '4V5B', '4V5H', '4V5Y', '4V64', '4V65', '4V66', '4V69', '4V6C', '4V6D', '4V6E', '4V6K', '4V6L', '4V6M', '4V6N', '4V6O', '4V6P', '4V6Q', '4V6R', '4V6S', '4V6T', '4V6V', '4V6Y', '4V6Z', '4V70', '4V71', '4V72', '4V73', '4V74', '4V75', '4V76', '4V77', '4V78', '4V79', '4V7A', '4V7B', '4V7C', '4V7D', '4V7I', '4V7S', '4V7T', '4V7U', '4V7V', '4V85', '4V89', '4V9C', '4V9D', '4V9O', '4V9P', '4WF1', '4WOI', '4WWW', '4YBB', '5AFI', '5H5U', '5IQR', '5IT8', '5J5B', '5J7L', '5J88', '5J8A', '5J91', '5JC9', '5JTE', '5JU8', '5KCR', '5KCS', '5KPS', '5KPV', '5KPW', '5KPX', '5L3P', '5LZA', '5LZB', '5LZC', '5LZD', '5LZE', '5LZF', '5MDV', '5MDW', '5MDY', '5MDZ', '5ME0', '5ME1', '5MGP', '5MY1', '5NO2', '5NO3', '5NO4', '5NP6', '5NWY', '5O2R', '5U4I', '5U4J', '5U9F', '5U9G', '5UYK', '5UYL', '5UYM', '5UYN', '5UYP', '5UYQ', '5UZ4', '5WDT', '5WE4', '5WE6', '5WF0', '5WFK', '5WFS', '6AWB', '6AWC', '6AWD', '6BU8', '6BY1', '6C4I', '6DNC', '6ENF', '6ENJ', '6ENU', '6GWT', '6GXM', '6GXN', '6GXO', '6GXP', '6H4N', '6H58', '6HRM', '6I7V', '6NQB', '6O7K', '6O9J', '6O9K', '6OFX', '6OG7', '6OGF', '6OGG', '6OGI', '6OM6', '6ORE', '6ORL', '6OSK', '6OSQ', '6OST', '6OT3', '6OUO', '6Q97', '6Q98', '6Q9A', '6SZS', '6TBV', '6TC3', '6TQO', '6VU3', '6VWL', '6VWM', '6VWN', '6VYQ', '6VYR', '6VYS', '6VYT', '6VYU', '6VYW', '6VYX', '6VYY', '6VYZ', '6VZ2', '6VZ3', '6VZ5', '6VZ7', '6VZJ', '6W6K', '6W77', '6W7M', '6W7N', '6W7W', '6WD0', '6WD1', '6WD2', '6WD3', '6WD4', '6WD5', '6WD6', '6WD7', '6WD8', '6WD9', '6WDA', '6WDB', '6WDC', '6WDD', '6WDE', '6WDF', '6WDG', '6WDH', '6WDI', '6WDJ', '6WDK', '6WDL', '6WDM', '6WNV', '6WNW', '6X6T', '6X7F', '6X7K', '6X9Q', '6XDQ', '6XDR', '6XE0', '6XGF', '6XII', '6XIJ', '6XZA', '6XZB', '6Y69', '6ZTJ', '6ZTL', '6ZTM', '6ZTN', '6ZTO', '6ZTP', '6ZU1', '7ABZ', '7AC7', '7ACJ', '7ACR', '7AFI', '7AFL', '7AFO', '7B5K', '7BOD', '7BOE', '7BOF', '7BOG', '7BOH', '7BOI', '7D6Z', '7D80', '7JSS', '7JSW', '7JSZ', '7JT1', '7JT2', '7JT3', '7K00', '7K50', '7K51', '7K52', '7K53', '7K54', '7K55', '7LV0', '7M5D', '7N1P', '7N2C', '7N2U', '7N2V', '7N30', '7N31', '7NAR', '7NAS', '7NAT', '7NAU', '7NAV', '7NAX', '7NBU', '7O19', '7O1A', '7O1C', '7O5H', '7OE0', '7OE1', '7OI0', '7OIZ', '7OJ0', '7P3K', '7PJU', '7PJV', '7PJY', '7QG8', '7QGH', '7QGN', '7QGR', '7S1G', '7S1H', '7S1I', '7S1J', '7S1K', '7SA4', '7SS9', '7SSD', '7SSL', '7SSN', '7SSO', '7SSW', '7ST2', '7ST6', '7ST7', '7TOS', '7UG7', '7UPH', '7Y7C', '7Y7D', '7Y7E', '7Y7F', '7Y7G', '7Y7H', '7ZTA', '8A3L', '8AKN', '8AM9', '8AYE', '8B0X', '8B7Y', '8BF7', '8BGE', '8BGH', '8BH4', '8BHJ', '8BHL', '8BHN', '8BHP', '8BIL', '8BIM', '8CAI', '8CEP', '8CGJ', '8CGR', '8CGU', '8EIU', '8EKC', '8EMM', '8EYQ', '8EYT', '8FIZ', '8FTO', '8FZD', '8FZE', '8FZF', '8FZG', '8FZH', '8FZI', '8FZJ', '8G2U', '8G31', '8G34', '8G38', '8G6W', '8G7P', '8G7Q', '8G7R', '8G7S', '8GHU', '8HSP', '8HTZ', '8HU1', '8IFB', '8IFC', '8JSG', '8JSH', '8K3O', '8K4E', '8P16', '8P17', '8P18', '8PEG', '8PHJ', '8PKL', '8PVA', '8Q4F', '8QK7', '8QOA', '8R3V', '8R6C', '8R8M', '8RCL', '8RCM', '8RCS', '8RCT', '8SYL', '8T5D', '8T5H', '8UPO', '8UPR', '8UQL', '8UQM', '8UQP', '8UR0', '8URH', '8URI', '8URX', '8URY', '8VS9', '8VSA', '8YUO', '8YUP', '8YUQ', '8YUR', '8YUS', '9AX7', '9CG5', '9CG6', '9CG7', '9DUK', '9DUL', '9FBV', '9GFT', '9GGR', '9GUP', '9GUQ', '9GUS', '9GUT', '9GUU', '9GUV', '9GUW', '9GUX', '9MOR', '9MQ4']\n",
      "['1EG0.E']\n",
      "['2YKR.D']\n",
      "['3J9Y.C']\n",
      "['3J9Z.R']\n",
      "['3JA1.T']\n",
      "['3JBU.C']\n",
      "['3JBV.D']\n",
      "['3JCD.C']\n",
      "['3JCE.C']\n",
      "['3JCJ.PA']\n",
      "['3JCN.KA']\n",
      "['4A2I.D']\n",
      "['4ADV.D']\n",
      "['4U1U.D', '4U1U.CD']\n",
      "['4U1V.D', '4U1V.CD']\n",
      "['4U20.D', '4U20.CD']\n",
      "['4U24.D', '4U24.CD']\n",
      "['4U25.D', '4U25.CD']\n",
      "['4U26.D', '4U26.CD']\n",
      "['4U27.D', '4U27.CD']\n",
      "['4V47.DA']\n",
      "['4V48.FA']\n",
      "['4V4H.C', '4V4H.CD']\n",
      "['4V4Q.C', '4V4Q.CD']\n",
      "['4V4V.G']\n",
      "['4V4W.G']\n",
      "['4V50.F', '4V50.CD']\n",
      "['4V52.C', '4V52.CD']\n",
      "['4V53.C', '4V53.CD']\n",
      "['4V54.C', '4V54.CD']\n",
      "['4V55.C', '4V55.CD']\n",
      "['4V56.BB', '4V56.CD']\n",
      "['4V57.BB', '4V57.CD']\n",
      "['4V5B.JA', '4V5B.DD']\n",
      "['4V5H.D']\n",
      "['4V5Y.C', '4V5Y.CD']\n",
      "['4V64.C', '4V64.CD']\n",
      "['4V65.S']\n",
      "['4V66.S']\n",
      "['4V69.O']\n",
      "['4V6C.C', '4V6C.CD']\n",
      "['4V6D.C', '4V6D.CD']\n",
      "['4V6E.C', '4V6E.CD']\n",
      "['4V6K.OA']\n",
      "['4V6L.H']\n",
      "['4V6M.I']\n",
      "['4V6N.OA']\n",
      "['4V6O.G']\n",
      "['4V6P.G']\n",
      "['4V6Q.G']\n",
      "['4V6R.G']\n",
      "['4V6S.NA']\n",
      "['4V6T.D']\n",
      "['4V6V.O']\n",
      "['4V6Y.C']\n",
      "['4V6Z.C']\n",
      "['4V70.C']\n",
      "['4V71.C']\n",
      "['4V72.C']\n",
      "['4V73.C']\n",
      "['4V74.C']\n",
      "['4V75.C']\n",
      "['4V76.C']\n",
      "['4V77.C']\n",
      "['4V78.C']\n",
      "['4V79.C']\n",
      "['4V7A.C']\n",
      "['4V7B.D']\n",
      "['4V7C.D']\n",
      "['4V7D.LA']\n",
      "['4V7I.MA']\n",
      "['4V7S.D', '4V7S.CD']\n",
      "['4V7T.D', '4V7T.CD']\n",
      "['4V7U.D', '4V7U.CD']\n",
      "['4V7V.D', '4V7V.CD']\n",
      "['4V85.D']\n",
      "['4V89.D']\n",
      "['4V9C.D', '4V9C.CD']\n",
      "['4V9D.BA', '4V9D.BD']\n",
      "['4V9O.KA', '4V9O.DD', '4V9O.FD', '4V9O.HD']\n",
      "['4V9P.JA', '4V9P.DD', '4V9P.FD', '4V9P.HD']\n",
      "['4WF1.D', '4WF1.CD']\n",
      "['4WOI.D', '4WOI.DD']\n",
      "['4WWW.DB', '4WWW.XD']\n",
      "['4YBB.D', '4YBB.BD']\n",
      "['5AFI.D']\n",
      "['5H5U.PA']\n",
      "['5IQR.HA']\n",
      "['5IT8.D', '5IT8.BD']\n",
      "['5J5B.D', '5J5B.BD']\n",
      "['5J7L.D', '5J7L.BD']\n",
      "['5J88.D', '5J88.BD']\n",
      "['5J8A.D', '5J8A.BD']\n",
      "['5J91.D', '5J91.BD']\n",
      "['5JC9.D', '5JC9.BD']\n",
      "['5JTE.D']\n",
      "['5JU8.D']\n",
      "['5KCR.JA']\n",
      "['5KCS.LA']\n",
      "['5KPS.IA']\n",
      "['5KPV.HA']\n",
      "['5KPW.HA']\n",
      "['5KPX.HA']\n",
      "['5L3P.IA']\n",
      "['5LZA.D']\n",
      "['5LZB.D']\n",
      "['5LZC.D']\n",
      "['5LZD.D']\n",
      "['5LZE.D']\n",
      "['5LZF.D']\n",
      "['5MDV.OA']\n",
      "['5MDW.OA']\n",
      "['5MDY.OA']\n",
      "['5MDZ.MA']\n",
      "['5ME0.D']\n",
      "['5ME1.D']\n",
      "['5MGP.IA']\n",
      "['5MY1.C']\n",
      "['5NO2.B']\n",
      "['5NO3.C']\n",
      "['5NO4.C']\n",
      "['5NP6.G']\n",
      "['5NWY.LA']\n",
      "['5O2R.LA']\n",
      "['5U4I.IA']\n",
      "['5U4J.D']\n",
      "['5U9F.QA']\n",
      "['5U9G.QA']\n",
      "['5UYK.HA']\n",
      "['5UYL.HA']\n",
      "['5UYM.HA']\n",
      "['5UYN.HA']\n",
      "['5UYP.HA']\n",
      "['5UYQ.HA']\n",
      "['5UZ4.C']\n",
      "['5WDT.KA']\n",
      "['5WE4.KA']\n",
      "['5WE6.KA']\n",
      "['5WF0.KA']\n",
      "['5WFK.KA']\n",
      "['5WFS.KA']\n",
      "['6AWB.J']\n",
      "['6AWC.J']\n",
      "['6AWD.I']\n",
      "['6BU8.HA']\n",
      "['6BY1.OA', '6BY1.BD']\n",
      "['6C4I.KA']\n",
      "['6DNC.PA']\n",
      "['6ENF.D']\n",
      "['6ENJ.HA']\n",
      "['6ENU.D']\n",
      "['6GWT.KA']\n",
      "['6GXM.KA']\n",
      "['6GXN.KA']\n",
      "['6GXO.KA']\n",
      "['6GXP.JA']\n",
      "['6H4N.D']\n",
      "['6H58.IA', '6H58.dd']\n",
      "['6HRM.JA']\n",
      "['6I7V.CA', '6I7V.BD']\n",
      "['6NQB.F']\n",
      "['6O7K.R']\n",
      "['6O9J.HA']\n",
      "['6O9K.D']\n",
      "['6OFX.EA']\n",
      "['6OG7.EA']\n",
      "['6OGF.EA']\n",
      "['6OGG.EA']\n",
      "['6OGI.EA']\n",
      "['6OM6.JA']\n",
      "['6ORE.LA']\n",
      "['6ORL.HA']\n",
      "['6OSK.JA']\n",
      "['6OSQ.KA']\n",
      "['6OST.HA']\n",
      "['6OT3.JA']\n",
      "['6OUO.JA']\n",
      "['6Q97.OA']\n",
      "['6Q98.MA']\n",
      "['6Q9A.MA']\n",
      "['6SZS.IA']\n",
      "['6TBV.D']\n",
      "['6TC3.D']\n",
      "['6TQO.L']\n",
      "['6VU3.X']\n",
      "['6VWL.HA']\n",
      "['6VWM.HA']\n",
      "['6VWN.HA']\n",
      "['6VYQ.X']\n",
      "['6VYR.X']\n",
      "['6VYS.X']\n",
      "['6VYT.W']\n",
      "['6VYU.X']\n",
      "['6VYW.X']\n",
      "['6VYX.X']\n",
      "['6VYY.X']\n",
      "['6VYZ.X']\n",
      "['6VZ2.X']\n",
      "['6VZ3.X']\n",
      "['6VZ5.X']\n",
      "['6VZ7.X']\n",
      "['6VZJ.W']\n",
      "['6W6K.C']\n",
      "['6W77.C']\n",
      "['6W7M.D']\n",
      "['6W7N.C']\n",
      "['6W7W.B']\n",
      "['6WD0.GA']\n",
      "['6WD1.GA']\n",
      "['6WD2.GA']\n",
      "['6WD3.GA']\n",
      "['6WD4.GA']\n",
      "['6WD5.GA']\n",
      "['6WD6.GA']\n",
      "['6WD7.GA']\n",
      "['6WD8.GA']\n",
      "['6WD9.GA']\n",
      "['6WDA.GA']\n",
      "['6WDB.GA']\n",
      "['6WDC.GA']\n",
      "['6WDD.GA']\n",
      "['6WDE.GA']\n",
      "['6WDF.GA']\n",
      "['6WDG.GA']\n",
      "['6WDH.GA']\n",
      "['6WDI.GA']\n",
      "['6WDJ.GA']\n",
      "['6WDK.GA']\n",
      "['6WDL.GA']\n",
      "['6WDM.GA']\n",
      "['6WNV.FA']\n",
      "['6WNW.HA']\n",
      "['6X6T.Z']\n",
      "['6X7F.Z']\n",
      "['6X7K.Z']\n",
      "['6X9Q.Z']\n",
      "['6XDQ.Z']\n",
      "['6XDR.Y']\n",
      "['6XE0.C']\n",
      "['6XGF.Y']\n",
      "['6XII.Y']\n",
      "['6XIJ.X']\n",
      "['6XZA.D']\n",
      "['6XZB.D']\n",
      "['6Y69.D']\n",
      "['6ZTJ.D']\n",
      "['6ZTL.D']\n",
      "['6ZTM.D']\n",
      "['6ZTN.D']\n",
      "['6ZTO.D']\n",
      "['6ZTP.D']\n",
      "['6ZU1.D']\n",
      "['7ABZ.OA']\n",
      "['7AC7.OA']\n",
      "['7ACJ.LA']\n",
      "['7ACR.LA']\n",
      "['7AFI.B']\n",
      "['7AFL.B']\n",
      "['7AFO.B']\n",
      "['7B5K.IA']\n",
      "['7BOD.B']\n",
      "['7BOE.D']\n",
      "['7BOF.B']\n",
      "['7BOG.B']\n",
      "['7BOH.D']\n",
      "['7BOI.B']\n",
      "['7D6Z.QA']\n",
      "['7D80.K']\n",
      "['7JSS.EA']\n",
      "['7JSW.EA']\n",
      "['7JSZ.GA']\n",
      "['7JT1.EA']\n",
      "['7JT2.FA']\n",
      "['7JT3.GA']\n",
      "['7K00.D']\n",
      "['7K50.HA']\n",
      "['7K51.HA']\n",
      "['7K52.HA']\n",
      "['7K53.HA']\n",
      "['7K54.HA']\n",
      "['7K55.HA']\n",
      "['7LV0.HA']\n",
      "['7M5D.KA']\n",
      "['7N1P.D']\n",
      "['7N2C.D']\n",
      "['7N2U.D']\n",
      "['7N2V.D']\n",
      "['7N30.D']\n",
      "['7N31.D']\n",
      "['7NAR.D']\n",
      "['7NAS.B']\n",
      "['7NAT.D']\n",
      "['7NAU.D']\n",
      "['7NAV.D']\n",
      "['7NAX.D']\n",
      "['7NBU.D']\n",
      "['7O19.D']\n",
      "['7O1A.D']\n",
      "['7O1C.D']\n",
      "['7O5H.D']\n",
      "['7OE0.B']\n",
      "['7OE1.B']\n",
      "['7OI0.A']\n",
      "['7OIZ.D']\n",
      "['7OJ0.D']\n",
      "['7P3K.D']\n",
      "['7PJU.KA']\n",
      "['7PJV.KA']\n",
      "['7PJY.KA']\n",
      "['7QG8.NA']\n",
      "['7QGH.MA']\n",
      "['7QGN.OA']\n",
      "['7QGR.MA']\n",
      "['7S1G.I']\n",
      "['7S1H.G']\n",
      "['7S1I.I']\n",
      "['7S1J.G']\n",
      "['7S1K.I']\n",
      "['7SA4.OA']\n",
      "['7SS9.NA']\n",
      "['7SSD.OA']\n",
      "['7SSL.OA']\n",
      "['7SSN.KA']\n",
      "['7SSO.OA']\n",
      "['7SSW.MA']\n",
      "['7ST2.OA']\n",
      "['7ST6.NA']\n",
      "['7ST7.RA']\n",
      "['7TOS.HA']\n",
      "['7UG7.D']\n",
      "['7UPH.W']\n",
      "['7Y7C.D']\n",
      "['7Y7D.D']\n",
      "['7Y7E.D']\n",
      "['7Y7F.D']\n",
      "['7Y7G.D']\n",
      "['7Y7H.D']\n",
      "['7ZTA.D']\n",
      "['8A3L.D']\n",
      "['8AKN.J']\n",
      "['8AM9.I']\n",
      "['8AYE.J']\n",
      "['8B0X.H']\n",
      "['8B7Y.GA']\n",
      "['8BF7.FA']\n",
      "['8BGE.EA']\n",
      "['8BGH.FA']\n",
      "['8BH4.EA']\n",
      "['8BHJ.EA']\n",
      "['8BHL.EA']\n",
      "['8BHN.FA']\n",
      "['8BHP.FA']\n",
      "['8BIL.FA']\n",
      "['8BIM.FA']\n",
      "['8CAI.D']\n",
      "['8CEP.B']\n",
      "['8CGJ.D']\n",
      "['8CGR.B']\n",
      "['8CGU.B']\n",
      "['8EIU.I']\n",
      "['8EKC.D']\n",
      "['8EMM.KA']\n",
      "['8EYQ.A']\n",
      "['8EYT.C']\n",
      "['8FIZ.I']\n",
      "['8FTO.I']\n",
      "['8FZD.D']\n",
      "['8FZE.D']\n",
      "['8FZF.D']\n",
      "['8FZG.D']\n",
      "['8FZH.D']\n",
      "['8FZI.D']\n",
      "['8FZJ.D']\n",
      "['8G2U.FA']\n",
      "['8G31.EA']\n",
      "['8G34.NA']\n",
      "['8G38.FA']\n",
      "['8G6W.I']\n",
      "['8G7P.D']\n",
      "['8G7Q.D']\n",
      "['8G7R.D']\n",
      "['8G7S.D']\n",
      "['8GHU.D']\n",
      "['8HSP.D']\n",
      "['8HTZ.D']\n",
      "['8HU1.D']\n",
      "['8IFB.D']\n",
      "['8IFC.D']\n",
      "['8JSG.H']\n",
      "['8JSH.G']\n",
      "['8K3O.C']\n",
      "['8K4E.D']\n",
      "['8P16.D']\n",
      "['8P17.D']\n",
      "['8P18.D']\n",
      "['8PEG.M']\n",
      "['8PHJ.N']\n",
      "['8PKL.M']\n",
      "['8PVA.D']\n",
      "['8Q4F.I']\n",
      "['8QK7.D']\n",
      "['8QOA.H']\n",
      "['8R3V.N', '8R3V.D2']\n",
      "['8R6C.J']\n",
      "['8R8M.PA']\n",
      "['8RCL.N', '8RCL.D2']\n",
      "['8RCM.N', '8RCM.D2']\n",
      "['8RCS.O', '8RCS.D2']\n",
      "['8RCT.O', '8RCT.D2']\n",
      "['8SYL.D']\n",
      "['8T5D.FA']\n",
      "['8T5H.EA']\n",
      "['8UPO.X']\n",
      "['8UPR.Y']\n",
      "['8UQL.Y']\n",
      "['8UQM.Z']\n",
      "['8UQP.Y']\n",
      "['8UR0.Z']\n",
      "['8URH.Y']\n",
      "['8URI.Z']\n",
      "['8URX.Y']\n",
      "['8URY.Z']\n",
      "['8VS9.NA']\n",
      "['8VSA.NA']\n",
      "['8YUO.D']\n",
      "['8YUP.D']\n",
      "['8YUQ.D']\n",
      "['8YUR.D']\n",
      "['8YUS.D']\n",
      "['9AX7.I']\n",
      "['9CG5.I']\n",
      "['9CG6.I']\n",
      "['9CG7.I']\n",
      "['9DUK.C']\n",
      "['9DUL.D']\n",
      "['9FBV.GA']\n",
      "['9GFT.D', '9GFT.AD']\n",
      "['9GGR.D', '9GGR.AD']\n",
      "['9GUP.E']\n",
      "['9GUQ.E']\n",
      "['9GUS.E']\n",
      "['9GUT.E']\n",
      "['9GUU.E']\n",
      "['9GUV.E']\n",
      "['9GUW.E']\n",
      "['9GUX.E']\n",
      "['9MOR.OA']\n",
      "['9MQ4.OA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@> Parsing in 331.3s.\n",
      "2025-08-09 01:36:29,046 [DEBUG]-logger.debug: Parsing in 331.3s.\n",
      "@> Parse UniProt information of P0A7X3...\n",
      "2025-08-09 01:36:35,408 [INFO]-logger.info: Parse UniProt information of P0A7X3...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2YKR', '3IY8', '3J9Y', '3J9Z', '3JA1', '3JBU', '3JBV', '3JCD', '3JCE', '3JCJ', '3JCN', '4A2I', '4ADV', '4U1U', '4U1V', '4U20', '4U24', '4U25', '4U26', '4U27', '4V47', '4V48', '4V4H', '4V4Q', '4V4V', '4V4W', '4V50', '4V52', '4V53', '4V54', '4V55', '4V56', '4V57', '4V5B', '4V5H', '4V5Y', '4V64', '4V65', '4V66', '4V69', '4V6C', '4V6D', '4V6E', '4V6K', '4V6L', '4V6M', '4V6N', '4V6O', '4V6P', '4V6Q', '4V6R', '4V6S', '4V6T', '4V6V', '4V6Y', '4V6Z', '4V70', '4V71', '4V72', '4V73', '4V74', '4V75', '4V76', '4V77', '4V78', '4V79', '4V7A', '4V7B', '4V7C', '4V7D', '4V7I', '4V7S', '4V7T', '4V7U', '4V7V', '4V85', '4V89', '4V9C', '4V9D', '4V9O', '4V9P', '4WF1', '4WOI', '4WWW', '4YBB', '5AFI', '5H5U', '5IQR', '5IT8', '5J5B', '5J7L', '5J88', '5J8A', '5J91', '5JC9', '5JTE', '5JU8', '5KCR', '5KCS', '5KPS', '5KPV', '5KPW', '5KPX', '5L3P', '5LZA', '5LZB', '5LZC', '5LZD', '5LZE', '5LZF', '5MDV', '5MDW', '5MDY', '5MDZ', '5ME0', '5ME1', '5MGP', '5MY1', '5NO2', '5NO3', '5NO4', '5NP6', '5NWY', '5O2R', '5U4I', '5U9F', '5U9G', '5UYK', '5UYL', '5UYM', '5UYN', '5UYP', '5UYQ', '5UZ4', '5WDT', '5WE4', '5WE6', '5WF0', '5WFK', '5WFS', '6AWB', '6AWC', '6AWD', '6BU8', '6BY1', '6C4I', '6DNC', '6ENF', '6ENJ', '6ENU', '6GWT', '6GXM', '6GXN', '6GXO', '6GXP', '6H4N', '6H58', '6HRM', '6I7V', '6O7K', '6O9J', '6O9K', '6OFX', '6OG7', '6OGF', '6OGG', '6OGI', '6OM6', '6ORE', '6ORL', '6OSK', '6OSQ', '6OST', '6OT3', '6OUO', '6Q98', '6Q9A', '6SZS', '6TBV', '6TC3', '6VU3', '6VWL', '6VWM', '6VWN', '6VYQ', '6VYR', '6VYS', '6VYT', '6VYU', '6VYW', '6VYX', '6VYY', '6VYZ', '6VZ2', '6VZ3', '6VZ5', '6VZ7', '6VZJ', '6W6K', '6W77', '6W7M', '6W7N', '6WD0', '6WD1', '6WD2', '6WD3', '6WD4', '6WD5', '6WD6', '6WD7', '6WD8', '6WD9', '6WDA', '6WDB', '6WDC', '6WDD', '6WDE', '6WDF', '6WDG', '6WDH', '6WDI', '6WDJ', '6WDK', '6WDL', '6WDM', '6WNV', '6WNW', '6X6T', '6X7F', '6X7K', '6X9Q', '6XDQ', '6XDR', '6XE0', '6XGF', '6XII', '6XIJ', '6XZA', '6XZB', '6Y69', '6ZTJ', '6ZTL', '6ZTM', '6ZTN', '6ZTO', '6ZTP', '6ZU1', '7ABZ', '7AC7', '7ACJ', '7ACR', '7AF3', '7AF5', '7AF8', '7AFA', '7AFD', '7AFH', '7AFK', '7AFN', '7B5K', '7BOE', '7BOH', '7D6Z', '7D80', '7JSS', '7JSW', '7JSZ', '7JT1', '7JT2', '7JT3', '7K00', '7K50', '7K51', '7K52', '7K53', '7K54', '7K55', '7LV0', '7M5D', '7N1P', '7N2C', '7N2U', '7N2V', '7N30', '7N31', '7NAR', '7NAT', '7NAU', '7NAV', '7NAX', '7NBU', '7O19', '7O1A', '7O1C', '7OE0', '7OE1', '7OIZ', '7OJ0', '7P3K', '7PJU', '7PJV', '7PJY', '7QG8', '7QGH', '7QGN', '7QGR', '7S1G', '7S1H', '7S1I', '7S1J', '7S1K', '7SA4', '7SS9', '7SSD', '7SSL', '7SSN', '7SSO', '7SSW', '7ST2', '7ST6', '7ST7', '7TOS', '7UG7', '7UPH', '7Y7C', '7Y7D', '7Y7E', '7Y7F', '7Y7G', '7Y7H', '7ZTA', '8A3L', '8AKN', '8AM9', '8AYE', '8B0X', '8B7Y', '8BF7', '8BGE', '8BGH', '8BH4', '8BHJ', '8BHL', '8BHN', '8BHP', '8BIL', '8BIM', '8CA7', '8CAZ', '8CF1', '8CF8', '8CGI', '8EIU', '8EKC', '8EMM', '8EYQ', '8EYT', '8FIZ', '8FTO', '8FZD', '8FZE', '8FZF', '8FZG', '8FZH', '8FZI', '8FZJ', '8G2U', '8G31', '8G34', '8G38', '8G6W', '8G7P', '8G7Q', '8G7R', '8G7S', '8HSP', '8HTZ', '8HU1', '8IFB', '8IFC', '8JSG', '8K3O', '8K4E', '8P16', '8P17', '8P18', '8PEG', '8PHJ', '8PKL', '8PVA', '8Q4F', '8QBT', '8QK7', '8QOA', '8R3V', '8R6C', '8R8M', '8RCL', '8RCM', '8RCS', '8RCT', '8SYL', '8T5D', '8T5H', '8UPO', '8UPR', '8UQL', '8UQM', '8UQP', '8UR0', '8URH', '8URI', '8URX', '8URY', '8VS9', '8VSA', '8YUO', '8YUP', '8YUQ', '8YUR', '8YUS', '9DUK', '9DUL', '9FBV', '9GFT', '9GGR', '9GUP', '9GUQ', '9GUS', '9GUT', '9GUU', '9GUV', '9GUW', '9GUX', '9MOR', '9MQ4']\n",
      "['2YKR.I']\n",
      "['3IY8.E']\n",
      "['3J9Y.T']\n",
      "['3J9Z.W']\n",
      "['3JA1.I']\n",
      "['3JBU.H']\n",
      "['3JBV.I']\n",
      "['3JCD.H']\n",
      "['3JCE.H']\n",
      "['3JCJ.SA']\n",
      "['3JCN.NA']\n",
      "['4A2I.I']\n",
      "['4ADV.I']\n",
      "['4U1U.I', '4U1U.CI']\n",
      "['4U1V.KB', '4U1V.CI']\n",
      "['4U20.I', '4U20.CI']\n",
      "['4U24.I', '4U24.CI']\n",
      "['4U25.I', '4U25.CI']\n",
      "['4U26.I', '4U26.CI']\n",
      "['4U27.KB', '4U27.CI']\n",
      "['4V47.IA']\n",
      "['4V48.KA']\n",
      "['4V4H.H', '4V4H.CI']\n",
      "['4V4Q.H', '4V4Q.CI']\n",
      "['4V4V.L']\n",
      "['4V4W.L']\n",
      "['4V50.K', '4V50.CI']\n",
      "['4V52.H', '4V52.CI']\n",
      "['4V53.H', '4V53.CI']\n",
      "['4V54.H', '4V54.CI']\n",
      "['4V55.H', '4V55.CI']\n",
      "['4V56.H', '4V56.CI']\n",
      "['4V57.H', '4V57.CI']\n",
      "['4V5B.OA', '4V5B.DI']\n",
      "['4V5H.I']\n",
      "['4V5Y.H', '4V5Y.CI']\n",
      "['4V64.H', '4V64.CI']\n",
      "['4V65.X']\n",
      "['4V66.X']\n",
      "['4V69.T']\n",
      "['4V6C.H', '4V6C.CI']\n",
      "['4V6D.JB', '4V6D.CI']\n",
      "['4V6E.H', '4V6E.CI']\n",
      "['4V6K.TA']\n",
      "['4V6L.M']\n",
      "['4V6M.N']\n",
      "['4V6N.TA']\n",
      "['4V6O.L']\n",
      "['4V6P.L']\n",
      "['4V6Q.L']\n",
      "['4V6R.L']\n",
      "['4V6S.SA']\n",
      "['4V6T.I']\n",
      "['4V6V.T']\n",
      "['4V6Y.H']\n",
      "['4V6Z.H']\n",
      "['4V70.H']\n",
      "['4V71.H']\n",
      "['4V72.H']\n",
      "['4V73.H']\n",
      "['4V74.H']\n",
      "['4V75.H']\n",
      "['4V76.H']\n",
      "['4V77.H']\n",
      "['4V78.H']\n",
      "['4V79.H']\n",
      "['4V7A.H']\n",
      "['4V7B.I']\n",
      "['4V7C.I']\n",
      "['4V7D.QA']\n",
      "['4V7I.RA']\n",
      "['4V7S.I', '4V7S.CI']\n",
      "['4V7T.I', '4V7T.CI']\n",
      "['4V7U.I', '4V7U.CI']\n",
      "['4V7V.I', '4V7V.CI']\n",
      "['4V85.I']\n",
      "['4V89.I']\n",
      "['4V9C.I', '4V9C.CI']\n",
      "['4V9D.GA', '4V9D.BI']\n",
      "['4V9O.PA', '4V9O.DI', '4V9O.FI', '4V9O.HI']\n",
      "['4V9P.OA', '4V9P.DI', '4V9P.FI', '4V9P.HI']\n",
      "['4WF1.I', '4WF1.CI']\n",
      "['4WOI.I', '4WOI.DI']\n",
      "['4WWW.NA', '4WWW.XI']\n",
      "['4YBB.DA', '4YBB.BI']\n",
      "['5AFI.I']\n",
      "['5H5U.UA']\n",
      "['5IQR.MA']\n",
      "['5IT8.I', '5IT8.BI']\n",
      "['5J5B.I', '5J5B.BI']\n",
      "['5J7L.JA', '5J7L.BI']\n",
      "['5J88.I', '5J88.BI']\n",
      "['5J8A.I', '5J8A.BI']\n",
      "['5J91.JA', '5J91.BI']\n",
      "['5JC9.I', '5JC9.BI']\n",
      "['5JTE.I']\n",
      "['5JU8.I']\n",
      "['5KCR.OA']\n",
      "['5KCS.QA']\n",
      "['5KPS.NA']\n",
      "['5KPV.MA']\n",
      "['5KPW.MA']\n",
      "['5KPX.MA']\n",
      "['5L3P.NA']\n",
      "['5LZA.I']\n",
      "['5LZB.I']\n",
      "['5LZC.I']\n",
      "['5LZD.I']\n",
      "['5LZE.I']\n",
      "['5LZF.I']\n",
      "['5MDV.TA']\n",
      "['5MDW.TA']\n",
      "['5MDY.TA']\n",
      "['5MDZ.RA']\n",
      "['5ME0.I']\n",
      "['5ME1.I']\n",
      "['5MGP.NA']\n",
      "['5MY1.H']\n",
      "['5NO2.G']\n",
      "['5NO3.H']\n",
      "['5NO4.H']\n",
      "['5NP6.L']\n",
      "['5NWY.QA']\n",
      "['5O2R.QA']\n",
      "['5U4I.NA']\n",
      "['5U9F.VA']\n",
      "['5U9G.VA']\n",
      "['5UYK.MA']\n",
      "['5UYL.MA']\n",
      "['5UYM.MA']\n",
      "['5UYN.MA']\n",
      "['5UYP.MA']\n",
      "['5UYQ.MA']\n",
      "['5UZ4.H']\n",
      "['5WDT.PA']\n",
      "['5WE4.PA']\n",
      "['5WE6.PA']\n",
      "['5WF0.PA']\n",
      "['5WFK.PA']\n",
      "['5WFS.PA']\n",
      "['6AWB.O']\n",
      "['6AWC.O']\n",
      "['6AWD.N']\n",
      "['6BU8.MA']\n",
      "['6BY1.TA', '6BY1.BI']\n",
      "['6C4I.PA']\n",
      "['6DNC.UA']\n",
      "['6ENF.I']\n",
      "['6ENJ.MA']\n",
      "['6ENU.I']\n",
      "['6GWT.PA']\n",
      "['6GXM.PA']\n",
      "['6GXN.PA']\n",
      "['6GXO.PA']\n",
      "['6GXP.OA']\n",
      "['6H4N.I']\n",
      "['6H58.NA', '6H58.ii']\n",
      "['6HRM.OA']\n",
      "['6I7V.HA', '6I7V.BI']\n",
      "['6O7K.W']\n",
      "['6O9J.MA']\n",
      "['6O9K.I']\n",
      "['6OFX.JA']\n",
      "['6OG7.JA']\n",
      "['6OGF.JA']\n",
      "['6OGG.JA']\n",
      "['6OGI.JA']\n",
      "['6OM6.OA']\n",
      "['6ORE.QA']\n",
      "['6ORL.MA']\n",
      "['6OSK.OA']\n",
      "['6OSQ.PA']\n",
      "['6OST.MA']\n",
      "['6OT3.OA']\n",
      "['6OUO.OA']\n",
      "['6Q98.RA']\n",
      "['6Q9A.RA']\n",
      "['6SZS.NA']\n",
      "['6TBV.I']\n",
      "['6TC3.I']\n",
      "['6VU3.CA']\n",
      "['6VWL.MA']\n",
      "['6VWM.MA']\n",
      "['6VWN.MA']\n",
      "['6VYQ.CA']\n",
      "['6VYR.CA']\n",
      "['6VYS.CA']\n",
      "['6VYT.BA']\n",
      "['6VYU.CA']\n",
      "['6VYW.CA']\n",
      "['6VYX.CA']\n",
      "['6VYY.CA']\n",
      "['6VYZ.CA']\n",
      "['6VZ2.CA']\n",
      "['6VZ3.CA']\n",
      "['6VZ5.CA']\n",
      "['6VZ7.CA']\n",
      "['6VZJ.BA']\n",
      "['6W6K.G']\n",
      "['6W77.G']\n",
      "['6W7M.I']\n",
      "['6W7N.F']\n",
      "['6WD0.LA']\n",
      "['6WD1.LA']\n",
      "['6WD2.LA']\n",
      "['6WD3.LA']\n",
      "['6WD4.LA']\n",
      "['6WD5.LA']\n",
      "['6WD6.LA']\n",
      "['6WD7.LA']\n",
      "['6WD8.LA']\n",
      "['6WD9.LA']\n",
      "['6WDA.LA']\n",
      "['6WDB.LA']\n",
      "['6WDC.LA']\n",
      "['6WDD.LA']\n",
      "['6WDE.LA']\n",
      "['6WDF.LA']\n",
      "['6WDG.LA']\n",
      "['6WDH.LA']\n",
      "['6WDI.LA']\n",
      "['6WDJ.LA']\n",
      "['6WDK.LA']\n",
      "['6WDL.LA']\n",
      "['6WDM.LA']\n",
      "['6WNV.KA']\n",
      "['6WNW.MA']\n",
      "['6X6T.EA']\n",
      "['6X7F.EA']\n",
      "['6X7K.EA']\n",
      "['6X9Q.EA']\n",
      "['6XDQ.EA']\n",
      "['6XDR.DA']\n",
      "['6XE0.H']\n",
      "['6XGF.DA']\n",
      "['6XII.DA']\n",
      "['6XIJ.CA']\n",
      "['6XZA.I']\n",
      "['6XZB.I']\n",
      "['6Y69.I']\n",
      "['6ZTJ.I']\n",
      "['6ZTL.I']\n",
      "['6ZTM.I']\n",
      "['6ZTN.I']\n",
      "['6ZTO.I']\n",
      "['6ZTP.I']\n",
      "['6ZU1.I']\n",
      "['7ABZ.TA']\n",
      "['7AC7.TA']\n",
      "['7ACJ.QA']\n",
      "['7ACR.QA']\n",
      "['7AF3.D']\n",
      "['7AF5.E']\n",
      "['7AF8.E']\n",
      "['7AFA.E']\n",
      "['7AFD.E']\n",
      "['7AFH.E']\n",
      "['7AFK.E']\n",
      "['7AFN.E']\n",
      "['7B5K.NA']\n",
      "['7BOE.I']\n",
      "['7BOH.I']\n",
      "['7D6Z.VA']\n",
      "['7D80.P']\n",
      "['7JSS.JA']\n",
      "['7JSW.JA']\n",
      "['7JSZ.LA']\n",
      "['7JT1.JA']\n",
      "['7JT2.KA']\n",
      "['7JT3.LA']\n",
      "['7K00.I']\n",
      "['7K50.MA']\n",
      "['7K51.MA']\n",
      "['7K52.MA']\n",
      "['7K53.MA']\n",
      "['7K54.MA']\n",
      "['7K55.MA']\n",
      "['7LV0.MA']\n",
      "['7M5D.PA']\n",
      "['7N1P.I']\n",
      "['7N2C.I']\n",
      "['7N2U.I']\n",
      "['7N2V.I']\n",
      "['7N30.I']\n",
      "['7N31.I']\n",
      "['7NAR.I']\n",
      "['7NAT.I']\n",
      "['7NAU.I']\n",
      "['7NAV.I']\n",
      "['7NAX.I']\n",
      "['7NBU.I']\n",
      "['7O19.I']\n",
      "['7O1A.I']\n",
      "['7O1C.I']\n",
      "['7OE0.P']\n",
      "['7OE1.Q']\n",
      "['7OIZ.I']\n",
      "['7OJ0.I']\n",
      "['7P3K.I']\n",
      "['7PJU.PA']\n",
      "['7PJV.PA']\n",
      "['7PJY.PA']\n",
      "['7QG8.SA']\n",
      "['7QGH.RA']\n",
      "['7QGN.TA']\n",
      "['7QGR.RA']\n",
      "['7S1G.SA']\n",
      "['7S1H.QA']\n",
      "['7S1I.SA']\n",
      "['7S1J.QA']\n",
      "['7S1K.SA']\n",
      "['7SA4.TA']\n",
      "['7SS9.SA']\n",
      "['7SSD.TA']\n",
      "['7SSL.TA']\n",
      "['7SSN.PA']\n",
      "['7SSO.TA']\n",
      "['7SSW.RA']\n",
      "['7ST2.TA']\n",
      "['7ST6.SA']\n",
      "['7ST7.JA']\n",
      "['7TOS.MA']\n",
      "['7UG7.I']\n",
      "['7UPH.BA']\n",
      "['7Y7C.I']\n",
      "['7Y7D.I']\n",
      "['7Y7E.I']\n",
      "['7Y7F.I']\n",
      "['7Y7G.I']\n",
      "['7Y7H.I']\n",
      "['7ZTA.I']\n",
      "['8A3L.I']\n",
      "['8AKN.O']\n",
      "['8AM9.N']\n",
      "['8AYE.O']\n",
      "['8B0X.M']\n",
      "['8B7Y.LA']\n",
      "['8BF7.KA']\n",
      "['8BGE.JA']\n",
      "['8BGH.KA']\n",
      "['8BH4.JA']\n",
      "['8BHJ.JA']\n",
      "['8BHL.JA']\n",
      "['8BHN.KA']\n",
      "['8BHP.KA']\n",
      "['8BIL.KA']\n",
      "['8BIM.KA']\n",
      "['8CA7.E']\n",
      "['8CAZ.F']\n",
      "['8CF1.F']\n",
      "['8CF8.E']\n",
      "['8CGI.E']\n",
      "['8EIU.N']\n",
      "['8EKC.I']\n",
      "['8EMM.PA']\n",
      "['8EYQ.N']\n",
      "['8EYT.L']\n",
      "['8FIZ.K']\n",
      "['8FTO.N']\n",
      "['8FZD.I']\n",
      "['8FZE.I']\n",
      "['8FZF.I']\n",
      "['8FZG.I']\n",
      "['8FZH.I']\n",
      "['8FZI.I']\n",
      "['8FZJ.I']\n",
      "['8G2U.KA']\n",
      "['8G31.JA']\n",
      "['8G34.GA']\n",
      "['8G38.KA']\n",
      "['8G6W.N']\n",
      "['8G7P.I']\n",
      "['8G7Q.I']\n",
      "['8G7R.I']\n",
      "['8G7S.I']\n",
      "['8HSP.I']\n",
      "['8HTZ.I']\n",
      "['8HU1.I']\n",
      "['8IFB.I']\n",
      "['8IFC.I']\n",
      "['8JSG.Q']\n",
      "['8K3O.H']\n",
      "['8K4E.I']\n",
      "['8P16.I']\n",
      "['8P17.I']\n",
      "['8P18.I']\n",
      "['8PEG.R']\n",
      "['8PHJ.S']\n",
      "['8PKL.R']\n",
      "['8PVA.I']\n",
      "['8Q4F.N']\n",
      "['8QBT.JA']\n",
      "['8QK7.I']\n",
      "['8QOA.M']\n",
      "['8R3V.X', '8R3V.I2']\n",
      "['8R6C.O']\n",
      "['8R8M.IA']\n",
      "['8RCL.X', '8RCL.I2']\n",
      "['8RCM.X', '8RCM.I2']\n",
      "['8RCS.Y', '8RCS.I2']\n",
      "['8RCT.Y', '8RCT.I2']\n",
      "['8SYL.I']\n",
      "['8T5D.KA']\n",
      "['8T5H.JA']\n",
      "['8UPO.CA']\n",
      "['8UPR.DA']\n",
      "['8UQL.DA']\n",
      "['8UQM.EA']\n",
      "['8UQP.DA']\n",
      "['8UR0.EA']\n",
      "['8URH.DA']\n",
      "['8URI.EA']\n",
      "['8URX.DA']\n",
      "['8URY.EA']\n",
      "['8VS9.SA']\n",
      "['8VSA.SA']\n",
      "['8YUO.I']\n",
      "['8YUP.I']\n",
      "['8YUQ.I']\n",
      "['8YUR.I']\n",
      "['8YUS.I']\n",
      "['9DUK.H']\n",
      "['9DUL.I']\n",
      "['9FBV.VA']\n",
      "['9GFT.I', '9GFT.AI']\n",
      "['9GGR.I', '9GGR.AI']\n",
      "['9GUP.J']\n",
      "['9GUQ.J']\n",
      "['9GUS.J']\n",
      "['9GUT.J']\n",
      "['9GUU.J']\n",
      "['9GUV.J']\n",
      "['9GUW.J']\n",
      "['9GUX.J']\n",
      "['9MOR.TA']\n",
      "['9MQ4.TA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@> Parsing in 334.0s.\n",
      "2025-08-09 01:42:09,399 [DEBUG]-logger.debug: Parsing in 334.0s.\n"
     ]
    }
   ],
   "source": [
    "id_list = ['P0A7V8', 'P0A7X3']\n",
    "data = []\n",
    "for id in id_list:\n",
    "    u = searchUniprot(id)\n",
    "    _dict = {\n",
    "        'id': u.getAccession(),\n",
    "        'name': u.getName(),\n",
    "        'protein': u.getProtein(),\n",
    "        'gene': u.getGene(),\n",
    "        'organism': u.getOrganism(),\n",
    "        'sequence': u.getSequence(),\n",
    "        'cell_location': u.getCellLocation(),\n",
    "        'cofactor': u.getCofactor(),\n",
    "        'binding_site': u.getBindingSite(),\n",
    "        'active_site': u.getActivateSite(),\n",
    "        'dna_binding': u.getDNAbinding(),\n",
    "        'zinc_finger': u.getZincFinger(),\n",
    "        'pdb': u.getPDBs(),\n",
    "        'alphafold': u.getAlphaFold(),\n",
    "    }\n",
    "    data.append(_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a94f88e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rcsbapi.search import AttributeQuery, NestedAttributeQuery\n",
    "\n",
    "\n",
    "def ChEBI2ligandID(ChEBI):\n",
    "    # Using ChEBI\n",
    "    q1 = AttributeQuery(\n",
    "        attribute=\"rcsb_chem_comp_related.resource_name\",\n",
    "        operator=\"exact_match\",\n",
    "        value=\"ChEBI\"  # can also use \"ChEMBL\", \"DrugBank\", or \"PubChem\"\n",
    "    )\n",
    "    q2 = AttributeQuery(\n",
    "        attribute=\"rcsb_chem_comp_related.resource_accession_code\",\n",
    "        operator=\"exact_match\",\n",
    "        value=[ChEBI],\n",
    "    )\n",
    "    q2 = NestedAttributeQuery(q1, q2)\n",
    "    r = list(q2(return_type=\"mol_definition\"))\n",
    "    return r[0]\n",
    "\n",
    "# ChEBI2ligandID('CHEBI:30413')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dabac90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON data\n",
    "# r\"string\" : raw string, making Python treat slash as a normal character\n",
    "json_path = \"/mnt/nas_1/YangLab/loci/druggable_dynomics/data/parseUniprot_20.json\"\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract UniProt ID and determine presence of cofactor\n",
    "output_data = []\n",
    "for entry in data:\n",
    "    uniprot_id = entry.get(\"id\", \"\")\n",
    "    has_cofactor = \"Yes\" if entry.get(\"cofactor\") else \"No\"\n",
    "    output_data.append({\"UniProt_id\": uniprot_id, \"cofactor\": has_cofactor})\n",
    "\n",
    "# Convert to DataFrame and save to CSV\n",
    "df = pd.DataFrame(output_data)\n",
    "# csv_path = r\"C:\\Users\\User\\Desktop\\Lab\\druggable_dynomics\\if_cofactors.csv\"\n",
    "# df.to_csv(csv_path, index=False)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6fa920ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity_ids': \"List of compound identifiers each includes entry_id and entity_id separated by '_', e.g. 1XXX_1\"}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rcsbapi.data import DataSchema\n",
    "\n",
    "schema = DataSchema()\n",
    "schema.get_input_id_dict(\"polymer_entities\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
